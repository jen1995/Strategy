{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab02.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "exiVWyV-HLoP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа 2. Композиции алгоритмов. Ранжирование.\n",
        "\n",
        "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
        "\n",
        "### Правила сдачи\n",
        "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_02.ipynb."
      ]
    },
    {
      "metadata": {
        "id": "uVgJJ4RWHLoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bias-Variance decomposition. Композиции алгоритмов\n",
        "\n",
        "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)\n",
        "\n",
        "Рассмотрим задачу регрессии со среднеквадратичной функцией потерь, а также некоторый алгоритм $a$. Тогда качество алгоритма $a$ может быть записано следующим образом:\n",
        "\n",
        "$$Q(a) = \\mathbb{E}_{X^l} \\mathbb{E}_{x,y}(a(x) - y)^2,$$\n",
        "\n",
        "где первое матожидание вычисляется по всевозможным обучающим выборкам $X^l$ размера $l$. К сожалению, на реальных данных эта формула неприменима из-за невозможности сгенерировать необходимые для оценки данные. Поэтому проведем приближенный численный эксперимент с эмпирическими оценками матожиданий.\n",
        "\n",
        "С помощью бутстраппинга можно просемплировать из обучающей выборки $N$ новых выборок того же размера, тем самым \"имитируя\" пространство всевозможных обучающих выборок, после чего обучить на каждой выбранный алгоритм. Обозначим вектор истинных меток тестовой выборки за $y \\in \\mathbb{R}^{m}$. Векторы прогнозов для объектов из тестовой выборки для каждой модели обозначим за $\\hat{y}_i \\in \\mathbb{R}^{m}, i \\in \\{1, .., N\\}$. Тогда средний квадрат ошибки по всем моделям на тестовой выборке запишется как\n",
        "\n",
        "$$error=\\frac{1}{N}\\sum_{i=1}^{N}MSE(y,\\hat{y}_i).$$\n",
        "\n",
        "Обозначим среднее предсказание за $$\\overline{y} = \\frac{1}{N}\\sum_{i=1}^{N} \\hat{y}_i.$$\n",
        "\n",
        "Тогда квадрат отклонения среднего предсказания и разброс прогнозов относительно среднего предсказания всех моделей на тестовой выборке от истинных меток запишутся следующим образом, соответственно:\n",
        "\n",
        "$$bias^2 = MSE(y, \\overline y),$$\n",
        "\n",
        "$$variance = \\frac{1}{N}\\sum_{i=1}^N MSE(\\hat{y}_i, \\overline y).$$\n"
      ]
    },
    {
      "metadata": {
        "id": "2zopUv9WHLoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Для начала рассмотрим в качестве алгоритма решающее дерево. Как известно, при увеличении высоты дерева алгоритм может быть сильно чувствителен к составу обучающей выборки. Чтобы подтвердить эти предположения, проведите следующие эксперименты."
      ]
    },
    {
      "metadata": {
        "id": "sGS8es31HLob",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загрузите [набор данных](http://archive.ics.uci.edu/ml/datasets/BlogFeedback). Каждый объект — пост в блоге. Он описывается различными признаками: длина текста поста, наличие наиболее частотных слов, день недели, количество комментариев за последние 24 часа и т.п., а так же целевым признаком — количеством комментариев к посту. Полный список признаков и описание находятся на странице датасета. \n",
        "\n",
        "Разбейте данные из файла **blogData_train.csv** на обучающую и тестовую выборки в пропорциях 1 к 4 соответственно. Обратите внимание, что обучающая выборка меньше тестовой. Такая большая тестовая выборка позволит сделать измерение качества моделей достаточно достоверным. "
      ]
    },
    {
      "metadata": {
        "id": "QwaK2QlPHLoe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import sklearn\n",
        "\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import DMatrix\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsc75OjZHLon",
        "colab_type": "code",
        "colab": {},
        "outputId": "5a257ac6-5530-49db-dbd6-8627e4d959c9"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('BlogFeedback/blogData_train.csv', header=None)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.30467</td>\n",
              "      <td>53.845657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.52416</td>\n",
              "      <td>32.44188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.30467</td>\n",
              "      <td>53.845657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.52416</td>\n",
              "      <td>32.44188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.30467</td>\n",
              "      <td>53.845657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.52416</td>\n",
              "      <td>32.44188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40.30467</td>\n",
              "      <td>53.845657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.52416</td>\n",
              "      <td>32.44188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.30467</td>\n",
              "      <td>53.845657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.52416</td>\n",
              "      <td>32.44188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 281 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0          1    2      3     4         5         6    7      8    9    \\\n",
              "0  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
              "1  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
              "2  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
              "3  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
              "4  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
              "\n",
              "   ...   271  272  273  274  275  276  277  278  279   280  \n",
              "0  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
              "1  ...   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
              "2  ...   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
              "3  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
              "4  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  27.0  \n",
              "\n",
              "[5 rows x 281 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "TE5DQNoWHLo1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(df)[:, :280], df[280], test_size=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "E7vLVvO1HLo7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(1 балл) Задание 1.** Постройте графики зависимости $error$, $bias^2$ и $variance$ от глубины решающего дерева (от 1 до 15 включительно) для $N=100$. "
      ]
    },
    {
      "metadata": {
        "id": "72Q8CVdUHLo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def subsample(X_train, y_train):\n",
        "    rnd_indices = np.random.choice(len(X_train), 2 * len(X_train))\n",
        "    return X_train[rnd_indices], y_train.iloc[rnd_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76N3c3lMHLpH",
        "colab_type": "code",
        "colab": {},
        "outputId": "7abe2707-3060-40a7-d419-6a7fae8d8835"
      },
      "cell_type": "code",
      "source": [
        "all_predictions = []\n",
        "for depth in range(1, 16):\n",
        "    predictions = []\n",
        "    for _ in tqdm(range(100)):\n",
        "        X_subsample, y_subsample = subsample(X_train, y_train)\n",
        "        clf = DecisionTreeRegressor(max_depth=depth)\n",
        "        clf.fit(X_subsample, y_subsample)\n",
        "        predictions.append(clf.predict(X_test))\n",
        "    all_predictions.append(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:17<00:00,  5.71it/s]\n",
            "100%|██████████| 100/100 [00:29<00:00,  3.36it/s]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.33it/s]\n",
            "100%|██████████| 100/100 [00:56<00:00,  1.76it/s]\n",
            "100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n",
            "100%|██████████| 100/100 [01:08<00:00,  1.45it/s]\n",
            "100%|██████████| 100/100 [01:19<00:00,  1.26it/s]\n",
            "100%|██████████| 100/100 [01:28<00:00,  1.12it/s]\n",
            "100%|██████████| 100/100 [01:35<00:00,  1.05it/s]\n",
            "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
            "100%|██████████| 100/100 [01:53<00:00,  1.13s/it]\n",
            "100%|██████████| 100/100 [02:00<00:00,  1.20s/it]\n",
            "100%|██████████| 100/100 [02:11<00:00,  1.32s/it]\n",
            "100%|██████████| 100/100 [02:09<00:00,  1.30s/it]\n",
            "100%|██████████| 100/100 [02:17<00:00,  1.38s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "yiM19O3lHLpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "variances = [np.mean([mean_squared_error(np.mean(predictions, axis=0), pred) \n",
        "                      for pred in predictions]) for predictions in all_predictions]\n",
        "\n",
        "biases = [mean_squared_error(y_test, np.mean(predictions, axis=0)) for predictions in all_predictions]\n",
        "\n",
        "errors = [np.mean([mean_squared_error(y_test, prediction) \n",
        "                  for prediction in predictions]) for predictions in all_predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mBi9abo9HLpc",
        "colab_type": "code",
        "colab": {},
        "outputId": "cfa43a55-d4ac-41a3-818a-f51ef17cc658"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.arange(1, 16), variances, label='variance')\n",
        "plt.plot(np.arange(1, 16), biases, label='bias_sq')\n",
        "plt.plot(np.arange(1, 16), errors, label='error')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFACAYAAABDZi6TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CNYuQEAeHLpr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(0.5 балла) Задание 2.** Являются ли какие-то из полученных графиков монотонными? А должны ли они быть монотонными, если бы гипотетически эксперименты были проведены на всевозможных выборках? Почему? Убедитесь численно, что верно bias-variance разложение ошибки: $$error = bias^2 + variance$$"
      ]
    },
    {
      "metadata": {
        "id": "WKc2OuX2HLps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Численно мы легко убедимся в том, что ошибка равна $bias^2 + variance$, просто нарисовав график их суммы. Он окажется совпадающим с графиком $error$. Графики variance и bias выглядят монотонными.\n",
        "\n",
        "Видно, что, начиная с некоторой высоты, ошибка монотонно растёт, хотя условия эксперимента для каждой из высот были одинаковы. На самом деле такого быть не должно, и ошибка должна колебаться случайным образом, так как подвыборки выбирались из обучающей выборки равномерно."
      ]
    },
    {
      "metadata": {
        "id": "O6iUL_3UHLpv",
        "colab_type": "code",
        "colab": {},
        "outputId": "329bcee1-a057-4694-997e-db75fd013a22"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.arange(1, 16), variances, label='variance')\n",
        "plt.plot(np.arange(1, 16), biases, label='bias_sq')\n",
        "plt.plot(np.arange(1, 16), errors, label='error')\n",
        "plt.plot(np.arange(1, 16), np.array(variances) + np.array(biases), label='error as a sum')\n",
        "plt.xlabel('Tree depth')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFACAYAAABDZi6TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xd8VGW+x/HPM5M66T0hhITQWyAk\n0sFEFBELuotiXURdXN3irruruE3d1at79epd13ax66KI2BVUWqQIAkF6b+m9T9pkZp77xwwhQBBI\nQiaT/N6v17xOmXPO/B5C8p3nzJnnKK01QgghhHAvBlcXIIQQQojzJwEuhBBCuCEJcCGEEMINSYAL\nIYQQbkgCXAghhHBDEuBCCCGEGzprgCulXldKFSuldrVY95RSap9SaodS6mOlVHCL5x5SSh1SSu1X\nSl3eYv1057pDSqn5Hd8UIYQQouc4lx74m8D0U9YtB4ZrrZOAA8BDAEqpocCNwDDnPi8qpYxKKSPw\nAnAFMBS4ybmtEEIIIdrgrAGutV4DlJ+y7huttdW5uBHo7ZyfCSzSWjdqrY8Ch4AxzschrfURrbUF\nWOTcVgghhBBt4NEBx7gDeN85H4sj0I/Lda4DyDll/dizHTg8PFwnJCR0QImuVVtbi5+fn6vLuOCk\nnd2LtLN7kXa6j8zMzFKtdcTZtmtXgCul/gxYgYXtOc4px5wHzAOIiori6aef7qhDu4zZbMbf39/V\nZVxw0s7uRdrZvUg73Ud6enrWuWzX5gBXSt0OXAVM1ScGVM8D4lps1tu5jh9ZfxKt9QJgAUBqaqpO\nS0tra4ldRkZGBt2hHWcj7exepJ3di7Sz+2nT18iUUtOBB4BrtNZ1LZ76DLhRKeWtlOoLDAA2AZuB\nAUqpvkopLxwXun3WvtKFEEKInuusPXCl1HtAGhCulMoFHsZx1bk3sFwpBbBRa/0LrfVupdRiYA+O\nU+u/1FrbnMf5FfA1YARe11rvvgDtEUIIIXqEswa41vqmVla/9iPbPw483sr6pcDS86pOCCGEEK2S\nkdiEEEIINyQBLoQQQrghCXAhhBDCDUmACyGEEG5IAlwIIYRwQx0xlKoQQgjhMo31Zg5lrqRo1xYK\ncnNYuetrxxNKoZQCx9edTyy3mNc4lpVBASeeV8rg2K+5m2tAnba/ART0n3AFUfFDOqWtLUmACyGE\ncBv1ddUczlxFYeZ6GvbswfdwPpEFDXjYIQbHo7MdekRJgAshhBDH1ddVc2jzSgq3rqdxzx5MhwuI\nKHSEdSxQ66MojQ8i+8pBBIxIpnfyRHbvO0RKSgpojdZ2ALRzXttPLLf6vHNUcK3tYNeAc9lub97m\n5P0dzw8fMKoT/1VO6FEBXmeuBMDkH+ziSoQQQrRUZ67k8JaVFG79zhnWhUQUOcK6N2D2VZT1CSI7\nZTCBScnEX5TOoIEpGAwnX8qVXWalV+II1zSik/WYAC/JO8SRa66h8vpLuHz+864uRwgheqzamnIO\nbV5B8baNNO7ei+lIAZGFjXhoR1jXmBRl8cFkjxlKUFIyCWOmMqjfyNPCuqfrMQEeEdufrdH+BHyU\ngeW+Orx8Ta4uSQghOkR9XTXVJXlUl+ZjLiukrryYxooymirLsVZWoc1mzPX1fPnlyyhvHwzeXhh8\nfDF4++Dh64vB2xdPXxMePr54mvzx9DHhbQrA08cPH1MAXiZ/fPyC8PbxP+8Qra0p59CmFRT98B2W\nPXvxO1JERFEjXs6wrvZTlMcHkzV2GMFJKSSMuYRBiUkS1uegxwQ4deUEjfEn6L0a1r/9JOl3/93V\nFQkhRDO73U5tdSlVJXnUlOZjLiuioaK0OYjtVdXo6hoMNbUYa+rxqrXgXdeEqc6Ot/XEcXycj+Ns\nCup9FNF2jZc1B0/budXT5HzUnbLe4gFNHoomT4XNw4DV04DN04DNywO7lwd2Tw+0lwcohV9uGRHF\nFry0437SVf4GKuKDyZ4wgqCk0fQdcymDEoZJWLdRzwlwnyDGBBaTEaEwLPwU211/w2jsOc0XQriO\ntcnCsV3ryd3yLbV796ArqjDU1OFhrse71oJPnRVTvcbDfmIff+fjOIsR6kwGGvw8sfh5UR8VRG2A\niYoAfwxBQXgGh+AVGopvSAR+YdEEhMcQFB6Lf3AkBoOh+T7ZNpuVhrpqLPVmGmqrsdTX0lhXQ1ND\nLZY6M00NdVjr67A21mGrr8fWUI+toQF7YwO6sdH5sECjBSwWlMWKwdLkmDY24WluwNhkx2CzUxsT\nRNakRIKTUug7ZiqD4odKWHegnpNgBiOGlNsx7HuOqG/9+P7DF5lww29cXZUQoptpGdbmnTvwOphD\nRK4ZnyaIwtGDrQkw0mjypMnPG3NoADWB/qjAAIxBQXiFhOIdEoZvaCR+oZEEhvciKKJ3h118azR6\n4BcQil9AaIccT7hOzwlwgOTbmLjqCTYF+VP7xjsgAS6EaIfjYZ2zOYPaXTtPC+tgTyiO9SMvbTB+\nw0cQmzKFoUmT8PTyOeuxhTibnhXgAVF4Dr2S2ryNxK01s235e4y6rLXbnQshxMmsTRaO7lhLbuaa\n08I6Gmg8Jax7p17MgKTJeHh6ubp00U31rAAHSL2DCTs/Z69vDCX/96IEuBDiNCeFtfM0eGReLd6t\nhfWIJHqnTJGwFp2u5wV4whT8IxIoGQ1915dyYMsKBqZe6uqqhBAuYrNaOLBlBXktetanhXVvf3LT\nhzh61hLWoovoeQFuMEDK7YwrepRszyhyX3iKgW9IgAvR3Vnq68jet4mifVupObQP67EcvPNKCM+r\nxSZhLdxQzwtwgFG3ELrqMb5LCSL++2zyDm0jtr9rxrIVQnQcu91Oaf4hcndvouLALhqOHEblFOJf\nUEVoeRNGDaE4HlX+Bqqi/Nif2puo8ROIuyiNAcMnSlgLt9EzA9wvHIZcQ3LTSso3+fLDv/9B7L8+\ndHVVQohzVF9XTc6eTRTv+4GaQ/uxZeXgnVdKSHE9fg0aX8AXx3enyyO8qYkPo2ZyL/z6DSBs4Eji\nho1hSHgsQPP3o4VwNz0zwAFS7yB21xJ+GNWL2FV7KC/MIjQ63tVVCSGc7HY7xTn7yNu92dGbPnoE\nY04hAQXVhFRaMWgIw/GoCDRQHRVA4YRYvBISCBowlJghKQzoN1J61KLb6rkBHj8Bwgcx0Fth2wob\nX3iYGf9409VVCdEjFece4EDGp1Qf2IM9KxffvDJCiuvxtYAJx6PRE8ojfKjqF0l1fCymxAFEDB5J\nn2HjGBIc6eomCNHpem6AKwWpcxn41XyWDRlC+JebqH2gXEYnEqITlOYfZu/KD6nasA7/XVlEFVua\ne9PlQUZqogPIn9IH78REggcMJXboGKIShsrwx0K00LN/G0beCCseIXpyL3z2VrF+wT+Y9vtnXV2V\nEN1ORXE2e1YsoWLDWvx2HiW6sJFwwN8TCvuHkHXZWGInX05iSjpD5E20EOekZwe4bwgMu46Rez5n\nRUIMpiXLafp1gwxzKEQ7VZbmsWflEsq/W4NpxxGiChoIBfw8oLBfMMfSUuk1ZRrDJl5Fsrfc2leI\ntujZAQ6QegeG7e/hPz2JkJc3sP6dp0i786+urkoIt1JdXsieVR9Stj4Dnx2HiM5rIATwM0JhYiBZ\nN4yi1+RpDJ00k1G+EthCdAQJ8N4XQeQwxqr9rI30wv6fj7DP/bPc8k6IH2GuKmX3qiWUrl+N945D\nROfUEaTBZISChACyfppE1ORLGTplJiNNga4uV4huSQLceTGbcekfsM+8mZhXMtj86QLGXvcLV1cm\nRJdRW1PO7tUfUrJuNV47DhCdXUugHUwGKIj3J+vaFKImTWXoxdeR1EG3vRRC/DgJcICkG2D535gU\nr9kSaKTm1ddBAlz0YHXmSop2rODLr1/Fc9t+YrLMBNjB1wCFffzIviqZiEnpDL34J4wICnN1uUL0\nSBLgAD5BMGIWXjuXUDPzGvq8s4adGR8yIu2nrq5MiAvOZrNydNd6cr5fRe32bfgcyCUqr44kO9gV\nFMSZyJ6RRPjEdIZdMosRQeGuLlkIgQT4CSlzYevbTJgymP0frKX45eckwEW3VJS1l0MbvqLyhy0Y\n9x0h4lgVpkZNNFDvBSXxgWRfOZLqqN5ceccfGBYa7eqShRCtkAA/LnY0xIwkYN8HFE0fTcInmRze\nsZZ+SZNdXZkQbVZTWczBDV9RnLke2+79hBwuJaTaRigQaIDiGB8KJvTDlDSSuDHpJLW481ZGRgaB\nEt5CdFkS4C2l3gGf38eYWX8g/4tM9v77Cfq9IgEu3IOlsY7DW1eTtymDhp278DtUQGRhI75APFAa\n6kH54Ghqhg0hOnUyA8ZOY4RccCaE25IAb2n4LPj6L0TkfMP3UwYQn3GQgqO7iOk73NWVCXESu91O\nzv4tZG1cQfX2rXjtzyIyx4y3FWIBs6+iNDGErEmjCB09hgHjr2BITF9Xly2E6EBnDXCl1OvAVUCx\n1nq4c10o8D6QABwDbtBaVyilFPAvYAZQB9yutd7q3GcO8BfnYR/TWr/VsU3pAN7+jivSf/gPI+a9\nh3n1r9j6779z5TOLXV2Z6OHKCo5ycMMyyrduQu09SNjRCgLqNBFAkAcU9fYj99JhBI4cTfy4Sxk0\nKFXGMhCimzuXHvibwPPA2y3WzQdWaq2fVErNdy4/CFwBDHA+xgIvAWOdgf8wkApoIFMp9ZnWuqKj\nGtJhUufClteIr9/Pl6m9iFmxk8rSPIKd9w4WorNYGutY99rjGBZ9QVSxhSAgACiJ8qI4OZ7qpOHE\njkljyOh0RspwpEL0OGcNcK31GqVUwimrZwJpzvm3gAwcAT4TeFtrrYGNSqlgpVSMc9vlWutyAKXU\ncmA68F67W9DRokc4Rmfb8jqJ9zwCd/yRDS8+whV/e8XVlYke4nhwe73zGTEVVvJ7+5J1y2QiUiYy\ncMIVDJNbZwohaPtn4FFa6wLnfCEQ5ZyPBXJabJfrXHem9adRSs0D5gFERUWRkZHRxhLbLtpvPINz\nn6Oh+Bg5/f2J/HQ9y8ctxdOrbb0cs9nsknZ0Nmln+9isFgrXLibum43EVNjIifEi584riU6ZgY/B\nQA2QuW0PsKfDX7s18vPsXqSd3U+7L2LTWmullO6IYpzHWwAsAEhNTdVpaWkddehzZxkD//MWydYf\nsN/7K0z3P4l572rS7nuqTYfLyMjAJe3oZNLOtmmyNLDujf/C662PGV1uJT/Wh4rfzePSWb9y6efY\n8vPsXqSd3U9b/zoUOU+N45wWO9fnAXEttuvtXHem9V2TlwlG3QR7PiV58hXkxZnwWvwV1iaLqysT\n3UiTpYHVCx5mQ/pFRD/7ARZfDyoe/QXpyzOZcMNv5CI0IcSPautfiM+AOc75OcCnLdb/TDmMA6qc\np9q/BqYppUKUUiHANOe6ritlLtibMOx4D585NxJRZuW79551dVWiG2iyNJDxyiNsSB9D9DOLsXp7\nUP7IPEdwz75PglsIcU7O5Wtk7+G4CC1cKZWL42ryJ4HFSqk7gSzgBufmS3F8hewQjq+RzQXQWpcr\npf4BbHZu9/fjF7R1WZGDoc8E2PIG436xke9eeoemtxZhv/WP8gdWtIm1ycLaN5/A+NaHRJU2URDj\nQ/nDt5M2+7fyf0oIcd7O5Sr0m87w1NRWttXAL89wnNeB18+rOldLnQsf/RyP3A003TiDXi98SuaX\nr3PR1Xe5ujLhRqxNFta9/SSGN5YQXdpEQYw35X/7ORfP/g1Go4ylJIRoG3nb/2OGXAO+obDldSbc\n+Seq/A2Uvfqaq6sSbsLaZCHjtX+w/pJUop56D5uHgbK/3snFK7Yw8eb7JbyFEO0iAf5jPH1g1M2w\nfym+tnoqr51E/P5Kdq//zNWViS7M2mTh29cfcwb3u9iNBsr+cgdTVm5h0i1/kOAWQnQICfCzSZkL\ndiv88A7j73mEOm849uL/uroq0QVZmyyseeO/WDf1IiL/eyF2o4HSP891BPetf5TgFkJ0KPmLcjbh\n/aHvFMh8i6BJv6Nw2kgSvthO1p7viR861tXViS7AZrOy/p2nsL++iKhiC0VRXpT86Xam3PJ7CW0h\nxAUjPfBzkTIXqrLh8CpSf/UwNgPs/Pdjrq5KuJjNZmXN2/9k7SUpRDzpuFVAyZ9+xuRVmUz52YMS\n3kKIC0r+wpyLwVeBXwRseZ2om95j88RE4tYcojhnP5Fxg1xdnehkdpuVte/8N9bX3iW6sJGiSC9K\n5v+MSbf8Hg9PL1eXJ4ToIaQHfi48vCD5VjjwFVTlMfTXD+Fhg83/ftTVlYlOVFNZzJo3/gv96P2E\nP/4GBpudkgdvY9LKzUy5/SEJbyFEp5Ie+LkaPQfW/S9sfZvE9If4MjmK6K+3UT2/kMDQaFdXJy4A\nm83Kgc3LOfbNRxg27aDXkWoi7FAY5kHxA7cw8bYHJLSFEC4jAX6uQvtCv0tg69sw5Y/E3/tbjD9/\niO9eepTpf37J1dWJDlKaf5hdyxZiXruO8F15BJntJAAFMT5kz0giKn062ieOi6de6upShRA9nAT4\n+UidC+/fCge/Zvjka/lqwJMEfbKGxvvNePv6u7o60QaWxjp2f/sx+SuX4pO5l+jceqIAP19F0Yhe\n1E+cwNDpNzEkfkjzPj3lVoVCiK5NAvx8DJwOATGw5Q0YfCWhd91BwIPPsv6NJ7jk3sddXZ04RzkH\nMtm/bBGW7zYRta8YUyPEK8hP8Cf7hvHEXXYNyeNmyOlxIUSXJgF+PoyekHwbrHkKKrJIvfouVj/3\nEh7vfY7t7kfla0NdlLmqjF0rFlH67UoCtx4iorSJWKA8yEjBuH4ET0lj+OU3MTw81tWlCiHEOZPE\nOV+jfwZrn4atb2GY+jc8b72eiH++w8b3n2Pizfe7ujoB2O12Dmau4Og3H8OmbfQ6VEmQDXw8oGBg\nCA3XpJJ4+U8ZP2Ky3AVMCOG2JMDPV3AcDJgGW9+BtIcYf8v9fL/gPerfXIj9RrktpKuUF2ax66t3\nqV67hrAd2QTX2IkHiqK8yJ42jMj0yxlx6WxGmQJdXaoQQnQICfC2SL3D8Z3wfV/iOexa6q+fRu8F\nS/nhm4WkTL/N1dX1GLvXf0bW0iV4bt5Nr+w6IgCTj6JoaBT1kyYwePqNDEkc4eoyhRDigpAAb4v+\nl0JQHGS+AcOuZeK8v7Jz4TLKF7wMEuAXXP7hHfzw1/tI3FrouPisjx9ZPx1D78uuZtTEa+TiMyFE\njyAB3hYGo+Oz8NWPQ9lhTGH9KL96PAmLvmPfpq8ZPOZyV1fYLTXWm1n1z98S8+F6ems4ev1Yxv/6\n7wyL7OPq0oQQotPJB7ZtlXwbKCNkvgnAuF8+Qr0XHHrhadfW1U1t/OhFvr90PAmL1pM/LIrQj/7D\njH+8SYiEtxCih5IAb6vAGBh0BWxbCNZGQiLiyJ86jIRNueQcyHR1dd1G1t5NLL1hMkF/+jfaoKj5\n5++YsSiDuIEpri5NCCFcSgK8PVLvgLoy2Ps5AKN//TBawfbn/uHiwtxfnbmSpX+eQ+WsOcTsLSXr\n1imM/2YjY2bOc3VpQgjRJUiAt0diOoQkOEZmA3oljiBrXDy9M/ZTmn/YtbW5Kbvdzvr3nmHrZZPo\n++EmclJiif7sA6b/5f/w8jW5ujwhhOgyJMDbw2CAlNshax2U7Adg8K/n422FTS/IrUbP15Gd6/h6\n1iRCH30Fq5eR+mcf4qq3VxDTd7irSxNCiC5HAry9Rt0KBs/mi9n6J6dxNCmCiKVbMFeVubY2N2Gu\nKuXLP95E7eyfE3m4guy5lzLhmw2MvuJnri5NCCG6LAnw9vKPgCFXOS5ma6oHIPYXv8K/XvPd/0kv\n/MfY7XbWvP0EOy5LI/HzbWSN60PcF59w+YP/xstbTpcLIcSPkQDvCKl3QEMV7P4EgJGX3EBOYgB+\nH67C0ljn4uK6poOZK1k+czwR//U29QGeWF54lKte/5rIuEGuLk0IIdyCBHhHSJgMYf1hy+vNqwLv\nmENolY31b/3ThYV1PdXlhXzxu1k03PYrwnJqyL37Si7+6ntGTr3B1aUJIYRbkQDvCEpBylzI3QRF\nuwEY85N7KIz2Ri38BLvN6uICXc9ut5PxyiPsmTaVvst2kzW5H32Xfcllv3tahj4VQog2kADvKKNu\nBqN381fKDAYD6pZriSqyUPT+Mz16cJe9G5ex4sqxRP3P+5hDfdCvPMFV//cFYTF9XV2aEEK4LQnw\njmIKhWHXwo73wVILwISfPcCx4WGMWnMU8zW38s30VL75n99RknfIxcV2joqSHL745Uzsc+8nuKiW\ngt/8hPRl3zN88rWuLk0IIdyeBHhHSpkLjdWw60MAvLxNXLFkHQcf/T3Hbp6EZ4OVuFe+oujSq1l2\n3QRWL3iY6vJCFxfd8Ww2Kytf+BMHL7+cvqsOcHTqIAZ8/TWX3Ps4RqPcP0cIITqCBHhH6jMOIgaf\ndDEbQGBUf6742yukZ2zD8M6/yLo6mcCCaqKfWczRKel8eXM66997hsZ6s4sK7zi71n7C6ulj6fXv\nj6mM8sP45rNc9fwnhETEubo0IYToVqQ71JGUcnylbNkDkP8D9Eo+bZNBF01j0EXTsNvt7MxYQs5H\n7xKx4QCBW19h15OvUjAmgaiZs0i+/Fa3urirrOAoxa8+SsSWQvz9DRT98SYunfsXDAZ5jyiEEBeC\nBHhHS5oNyx92XMx2zekBfpzBYGDkJTcw8pIbaLI08MPStyj+9CN6fX8U37VPsfnR/6FswmASZt3G\n0InXdKkgNFeVcjhzFcXbvqdx3z58jhQQUVDPEA3HrhjO5L/+m8DQaFeXKYQQ3ZoEeEfzDYbhP4Wd\nS2DaY+ATeNZdPL18GHPt3XDt3dSZK8n8eAE1X35JnxV7MH79EOvC/oo5LZmBN9xJ/5EXd0IjTijO\nPcCxLasp27EF+4EjBBwrIay0CS+gN2D2VZTFBZI7rR+Noybzkzm/6dT6hBCip2pXgCulfgfcBWhg\nJzAXiAEWAWFAJnCb1tqilPIG3gZSgDJgttb6WHtev8tKnQvb/gM7P4CL7jyvXU3+wUy+7QG47QEq\nS/PYuvhFLF+tJP7DzTR9uJmVsT40XTKOpJvupVfiiA4r2Wazkr13Ezlb11KzazuGQ1mEZFcSZLYT\nAAQAZSFGquPDMKf3JXh4Mgmp6QzqO7z57EBGRkaH1SOEEOLHtTnAlVKxwG+AoVrreqXUYuBGYAbw\nrNZ6kVLqZeBO4CXntEJr3V8pdSPwT2B2u1vQFcWmQPQIx2n01DvafJjg8FguufdxuPdxirL2sv39\nlzCsWE/8OxlUvJPBzn4BGC9PZ/QN9xIaHX/Ox62vq+bIDxkUbttI/Z7deB3JJzzPjK8FIoAQA5RE\neVM6ojdVgwcSkXQRiRdNZUh4bJvbIoQQomO19xS6B+CrlGoCTEABcAlws/P5t4BHcAT4TOc8wBLg\neaWU0lrrdtbQ9Rwfme3L+yGvYwZwiYofwrQHnoMH4NjuDex5fwF+qzOJfPEz8l7+jI1Dw/GbcTkp\nP70H/6Cw5v0qirM5smU1pds30bT/IH7HigkvbsTDDr2Aei8ojfUnf8ogTEOHET1qPAOT0xjh698h\ndQshhLgw2hzgWus8pdTTQDZQD3yD45R5pdb6+NihucDxblsskOPc16qUqsJxmr20rTV0aSOuh2/+\n6vhKWXDHjvOdMGw8CX8fj91uZ//3y8j+4C1C1u0m5L8XcujZheQlxaCarARllxNaacME9AEqAwxU\n9gkme+wwAoePJG70ZAYOvki+my2EEG5ItbUDrJQKAT7EcRq8EvgAR8/6Ea11f+c2ccAyrfVwpdQu\nYLrWOtf53GFgrNa69JTjzgPmAURFRaUsWrSoTfV1BQP3v0hU0WpWJD2Pd3DUBX0tu81K6b51sHEN\nffYUUu9jpLxXIA29YzD26U9Awgj8Qi7sKXCz2Yy/f/fvuUs7uxdpZ/fSHdqZnp6eqbVOPdt27el6\nXQoc1VqXACilPgImAsFKKQ9nL7w3kOfcPg+IA3KVUh5AEI6L2U6itV4ALABITU3VaWlp7SjRxQYG\nw4KvGVnwLtEz3gOvC3yP66mXwi8v7Ev8mIyMDNz653WOpJ3di7Sze+kp7YT2jcSWDYxTSpmUUgqY\nCuwBVgOznNvMAT51zn/mXMb5/Kpu+fl3S71GwZQ/El2UAa9cAkV7XF2REEKIbqLNAa61/h7HKfOt\nOL5CZsDRc34QuF8pdQjHZ9yvOXd5DQhzrr8fmN+Out3HJX9he9IjUFcGr6TD5tegm79vEUIIceG1\n6+olrfXDwMOnrD4CjGll2wbg+va8nruqCE2Gaevh47sdV6YfyYBrngPfEFeXJoQQwk11nfE5uzv/\nSLjlQ7js77B/Kbw8GbI3uroqIYQQbkoCvDMZDDDxPrjjGzAY4Y0ZsOYpsNtcXZkQQgg3IwHuCr1T\n4O41MOw6WPUYvD0TqgtcXZUQQgg3IgHuKj5B8NNXYeYLjtHaXp4IB752dVVCCCHchAS4KykFybfC\nvG8hIAbevQG+egisja6uTAghRBcnAd4VRAyEu1bCmHmw8UV47TIoO+zqqoQQQnRhEuBdhacPzHgK\nbnwXKrPh/6bAdvcdRlYIIcSFJQHe1Qy+En6xHmJGOr43/tHd0Fjj6qqEEEJ0MRLgXVFQLMz5HNIe\ngp2LHb3x/B9cXZUQQoguRAK8qzIYIW0+zPkCmhrg1ctgwwsyDKsQQghAArzrS5gI96yHAdPg6z85\nrlSv7Z63UBdCCHHuJMDdgSkUblwIM56GI9/CSxPh6BpXVyWEEMKFJMDdhVIw5ufw85XgHQBvXQMr\n/wE2q6srE0II4QIS4O4megTc/S0k3wJrn4Y3Zzi+diaEEKJHkQB3R15+jiFYf/oaFO2BlyfBnk9d\nXZUQQohOJAHuzkbMgl+shbD+sPhn8Plvoane1VUJIYToBBLg7i60L8z9ynGb0sw34JVLoHivq6sS\nQghxgXm4ugDRATy84LK/Q98p8PEvYEEaDLgMIgafeIT1dwzXKoQQoluQAO9O+l/qGIZ1xSOQuxn2\nLQVtczynDBCa6Az0QRAxxDENHwCevi4tWwghzovdDrUlUJMP1QUnprUl9CsuB8Nm8A11fAXXFOac\nD3Mse3i7uvoOIwHe3QREwXXIg/jmAAAgAElEQVQvOeatjVB2CEr2Qcl+x6n1kv1w4CuwH//6mYKQ\nBIh0BvrxHnv4QPAyuaoVQnQ/Wjt+Jy1mMHg43jgbvRxfERUnWOqgpgCq888wLQBzYYu/YU7KCKYw\nYhqqIffzMx/f088Z5iEtwj30lPnQk0Pf09Qlf04S4N2ZhzdEDXM8WrJaoPywI9iL950I+IPLwd7k\n3EhBcJ9Tgn0QhA8Cb/9Ob4oQLqO14+LQxhrno7qV+ZbraqChtW1qWvx+OSkDePg6Pt46derp28o6\nE3gcf+6U6RnXOfY12Bodv/tGT9eEkd0OdaWtB3LLnnRD1en7egVAYAwExDg+Kjw+H9jrxNQvAgxG\n1mVkkDZpPNSVQ325Y1pX5pwvg7qKFvPlUH7Usdza6x7n4XPmcPcNhUHTHWc4O5kEeE/k4eUI5sgh\n0DLbbU1QfuT0YD+8CmyWE9sF9XGEeeTgk3rsym51vHu2NzkGmLFbnfNNznmrc74J7LYT823d1m4F\nL3/wCQbf4NanHl6d/s/bIY6HhsXs/MNvAzRou3M8/FPnncto0LSY12eeb/UYJ+bDSnfC/oYWf+yd\n09OWOcvz6izPtVjW9lMe2vEx0Knr7bYWzx9f39p2px7PdtrziYf3Qs0np4fwScF7DgMmGb0dgyz5\nBDqm3oEQHOecDzixzsvPcbymerA2OKYt560N0FTnuAdCQ5Vjaq13TJvqHfPnUs8ppgCsPf7PbXCc\nBTB4OqdGR7Afn29e7wFGjxPzBk/n8x5n3v74sVBQW+wM5gKoKWz9DYx/lCOEw/pBwiRnOPc6eeod\ncH6N9fB27BcYc+772KxQf0q4Nwd/eYs3BGVQtNsxX1/h+H8UmigBLlzM6OnsbQ+CoTNPrLdZoeKo\nM9CPh/t+x3CutsbmzS4G6KwRXg0ejlNmLV6/VZ6mHw/45mlIx4S/tfGUEKg5EcKnrauGRvOZtzt+\n/YKLjADY5dISOkWswQvKg08O2uD4U8K4RQCfND0+79+5n63arC1Cve6U8D/lTYBzu8OH9tMvoU+L\nN8TH3wzbTrwhtltbvEk+5WFzvpm2NoLd3GJfa4vjtTyWzdErDoyB+ImtB7NfpOMNQldg9AD/CMfj\nXNnt0FDp+DvjAl3kX050aUYPx8Vu4QNgyNUn1tttUHHMEeqlBzhy+CCJ/Qae/O68+V26Z4t38sfn\nPc9x25a9Aef88Z6brcnRS6mvdPwiNU8rWllX6Ri1rn6HY9li/vF2txr+QQzNz4G8F04P5dZOkbZK\nOc4ceAc4/vAfDwL/yBNhcHzd8e2a26xaTA3nMH+m7Z3Lrc47tsnMzCQlZbSj5Oab4Dlnmu+Kdw7L\n57OtMjgfxhbzBjAYTl4+aRvVYjtjK9u18mix3do1a0lLSzuHn1sXYvQAY8B59UxzLBn0m5J24Wrq\niQwGx2l0F5EAF21nMDpOe4X1A64k25pB4qS0zq3B6Al+4Y7H+fqx8D++fGr4N1Tjb7GCZ5QjXIPj\nWwncU0M44OSw9vRz/OJ3cTUHqyE2xdVlCCHOQAJc9FxtDP9NGRnu12MTQnQ7Xb8bIIQQQojTSIAL\nIYQQbkgCXAghhHBDEuBCCCGEG5IAF0IIIdyQBLgQQgjhhiTAhRBCCDckAS6EEEK4IQlwIYQQwg21\nK8CVUsFKqSVKqX1Kqb1KqfFKqVCl1HKl1EHnNMS5rVJKPaeUOqSU2qGUGt0xTRBCCCF6nvb2wP8F\nfKW1HgyMBPYC84GVWusBwErnMsAVwADnYx7wUjtfWwghhOix2hzgSqkgHLeYfQ1Aa23RWlcCM4G3\nnJu9BVzrnJ8JvK0dNgLBSqnzuFmrEEIIIY5TuvlWfue5o1KjgAXAHhy970zgPiBPax3s3EYBFVrr\nYKXUF8CTWut1zudWAg9qrbecctx5OHroREVFpSxatKhN9XUlZrMZf39/V5dxwUk7uxdpZ/ci7XQf\n6enpmVrr1LNt1567kXkAo4Ffa62/V0r9ixOnywHQWmul1Hm9Q9BaL8DxxoDU1FTdHe76lNFD7l4l\n7exepJ3di7Sz+2nPZ+C5QK7W+nvn8hIcgV50/NS4c1rsfD4PiGuxf2/nOiGEEEKcpzYHuNa6EMhR\nSg1yrpqK43T6Z8Ac57o5wKfO+c+AnzmvRh8HVGmtC9r6+kIIIURP1p5T6AC/BhYqpbyAI8BcHG8K\nFiul7gSygBuc2y4FZgCHgDrntkIIIYRog3YFuNZ6G9DaB+1TW9lWA79sz+sJIYQQwkFGYhNCCCHc\nkAS4EEII4YYkwIUQQgg3JAEuhBBCuCEJcCGEEMINSYALIYQQbkgCXAghhHBDEuBCCCGEG5IAF0II\nIdyQBLgQQgjhhiTAhRBCCDckAS6EEEK4IQlwIYQQwg1JgAshhBBuSAJcCCGEcEMS4EIIIYQbkgAX\nQggh3JAEuBBCCOGGJMCFEEIINyQBLoQQQrghCXAhhBDCDUmACyGEEG7Iw9UFCCGEEF2B3a6pabBS\nUWehsr6JijoLVXWOaUVdE1XOaUWdhSrn85W1TTx3czLpgyI7vV4JcCGEEN2K1po6i80RwrUWKuua\nqKx3hG9l7YlwrqxrotI5PR7Kdn3m4wb5ehJs8iTY5EWonxeJ4X4Em7yIDvTpvMa1IAEuhBCiy7Pb\nNZX1TZTUNDoe5obm+VKzpXm+qLKOuuVfYbHZz3gsk5eREJOXM4w9iQn2JcTkSbCvY92J57wc601e\nBPl6YjSoTmzx2UmACyGEcAmtNbUW24lQrmmkpKaBEnPjaeFcam7E2kr32NvDQESANxEB3vQJMxHl\nWc+Qfn0cIex7cgiHmDwJMnni7WF0QWs7ngS4EEJ0E1prahqtFFU1UFjdQGFVA0XVjp5qbl4j39bs\nxsOg8DAa8DAojAblnJ5Y9jSevOxhPLGdh8GA0aha7Gs48Zzx5GWloKKu6eRwbqXXXN9kO60dRoMi\nzM+rOZgHRwc0z0cEeBPhf2Le39sDpU70jDMyMkhLG9KZ/+wuIwEuhBBuwGqzU2JubA7lwqoGCqsb\nm+eLqh2hXWc5PRADfTyw26xsKs7FZtdYbRqr3f6jn/deCMEmz+bwTe4TfFIQtwznEJMXhi52uror\nkgAXQggXMzdaTwnmhtOCuaSm8bTA9TQqIgN8iA7yYUhMIGmDIokO8iYq0IfoQMf6qEAffDyNzp5p\n2kn72+0am9aOULdrbDZNk91+0rLVudxkO75di+edU6vNftKyzW7HZocQkycRAd6E+3sT5u/VbU5d\ndxUS4EIIcQFprSmrtXCstJajpbVkldWRX1XfIqAbMTdaT9sv0MejOYAHRgUQHeQI5OhAx7roIB9C\n29lTNRgUBhSekqtuSQJcCCHaSWtNRV0TR0trOVZay7EyR1gfK6slq7SOmhYBbTQoogK8iQpyBPPk\nARGnBXN0oA++XpKq4sdJgAshxDmqqmviaFltc2/6WIv56oYTIW1Q0DvEREK4Hyl9QkgI9yMh3I++\nYX7EhvjiaZRBMEX7SYALIUQLNQ1NHCutaw7qY6W1zfMVdU3N2ykFvYJ86RvuxzWjepEQ5kdfZ1DH\nhZjw8pCQFheWBLgQosepbbQ6e891rDps4YuS7c2nvkvNlpO2jQnyISHMj+nDY+gbbmoO6rhQEz7y\n4bFwoXYHuFLKCGwB8rTWVyml+gKLgDAgE7hNa21RSnkDbwMpQBkwW2t9rL2vL4QQram32E6c4m7u\nTTt61iU1jSdtGxlQQkK4H1MHRzlOdYc7Tn/Hh/rJZ9Giy+qIHvh9wF4g0Ln8T+BZrfUipdTLwJ3A\nS85phda6v1LqRud2szvg9YUQPVRDk42ssjrn1d0tLh4rraOwuuGkbcP9vekbbiJtYIQzpP2IDzOR\ns2cr0y9Nd1ELhGi7dgW4Uqo3cCXwOHC/cgyHcwlws3OTt4BHcAT4TOc8wBLgeaWU0lp38lACQgh3\n0mi1kVNex9HSulN607UUVDfQ8i9ImJ8XCeF+TOwfTt9wE/FhJ4I6wMez1eOXHJABQ4R7am8P/H+B\nB4AA53IYUKm1Pn45Zi4Q65yPBXIAtNZWpVSVc/vSdtYghHBzWmuyy+s4VGxucXV3HcfKasmvrD9p\nAJMQkyfxYX6MTQwjIcyPhHCTM6T9CPJtPaSF6I5UWzvASqmrgBla63uVUmnAH4DbgY1a6/7ObeKA\nZVrr4UqpXcB0rXWu87nDwFitdekpx50HzAOIiopKWbRoUZvq60rMZjP+/v6uLuOCk3Z2LxeynVpr\nSuo1e8tt7C2zsa/cTmXjib9FJg+I8jMQZVJEmQxE+RmINikiTQb8vTq2xyw/z+6lO7QzPT09U2ud\nerbt2tMDnwhco5SaAfjg+Az8X0CwUsrD2QvvDeQ5t88D4oBcpZQHEITjYraTaK0XAAsAUlNT9alD\n/7mj1oYw7I6knd1LR7czv7KeDYfL+O5wGRuPlJFXWQ84PpuePDiMcYmhDI4OpG+4HyEmz5NuUHEh\nyc+ze+kp7YR2BLjW+iHgIYDjPXCt9S1KqQ+AWTiuRJ8DfOrc5TPn8gbn86vk828huq/i6gY2HClj\nw+EyNhwpI6usDnCcAh+XGMYvLk5kfL8w+kX4d1pYC9GdXIjvgT8ILFJKPQb8ALzmXP8a8I5S6hBQ\nDtx4AV5bCOEi5bUWNh4p47vDpWw4XMbhkloAAnw8GNs3jDnjExjfL4xBUQFypykhOkCHBLjWOgPI\ncM4fAca0sk0DcH1HvJ4QwvWq6prYeNTRw954pIx9hTUA+HkZuahvKLMvimN8YjhDewVilMAWosPJ\nSGxCiHNS09DE5mPlzafEd+dXozX4eBpIjQ/lj5f3Yny/MEbEBslY30J0AglwIUSrGq2aNQdKmj/H\n3plXhc2u8TIaSO4TzG+nDmR8vzBGxgXJfZ6FcAEJcCEEWmuyyurYnlvJjtwqtudU8kN2HTa9CQ+D\nYmRcMPem9WN8Yhij40NkDHAhugAJcCF6GK01hdUNbM+pYkduJTvzqtiRW0VVveNOW94eBob1CuTy\nBE9mpyeTGh+Cn7f8qRCiq5HfSiG6uYpaS3PPekduJdtzq5pv5mE0KAZFBTBjRDRJvYNJ6h3EwKgA\nPI0GMjIyuHhghIurF0KciQS4EN2IudHKrrwTQb0jt5KccseAKUpBYrgfk/uHk9Q7iKS4YIbGBMrp\ncCHclAS4EG6qocnG3oJqx2fWzh724RJz8809YoN9GRkXxC1j40nqHcSI2KAz3tBDCOF+JMCFcANW\nm52DxeaTetb7C2tosjnSOtzfm5G9g7gqKYaRzlPhYf7eLq5aCHEhSYAL0UVZbXa+2l3Iwo3Z/JBT\nQUOTHXCMbJbUO4i7JicysncQSb2DiQnykeFIhehhJMCF6GLMjVbe35zDG+uPkltRT3yYiZvG9Gnu\nWSeE+clQpEIICXAhuoqCqnreXH+MdzdlU9Ng5aKEEP561VAuHRIlQ5EKIU4jAS6Ei+3Kq+LVtUf4\nYkcBdq25YkQMP5+cyKi4YFeXJoTowiTAhXABu12zen8xr6w9wsYj5fh5GfnZ+ATmTkwgLtTk6vKE\nEG5AAlyITtTQZOOjrXm8tu4Ih0tqiQny4aErBnPjmD4E+cpXvIQQ504CXIhOUGpu5J0NWfxnYxZl\ntRaG9Qrkf2eP4sqkGLlzlxCiTSTAhbiADhWbeW3dET7cmofFamfq4EjumpzIuMRQ+dqXEKJdJMCF\n6GBaazYcKePVtUdZta8Ybw8DPx3dmzsn9aV/pL+ryxNCdBMS4EJ0kCabnS93FPDK2iPszq8mzM+L\n3146gNvGxcuoaEKIDicBLkQ7VdU3sWhTNm9+d4yCqgb6RfjxxE9GcF1yrNwoRAhxwUiAC9FGOeV1\nvLH+GO9vzqbWYmN8YhiPXzectIGRMlKaEOKCkwAX4jwdrrTxwcKtLNtVgEEprkqK4a7JiQyPDXJ1\naUKIHkQCXIhzUGZuZNmuQj7amsvW7AYCfEr4+eREbp+YQEyQr6vLE0L0QBLgQpxBdUMT3+wu4rPt\n+aw/VIrNrukX4cdNg734803p+HvLr48QwnXkL5AQLdRbbKzcV8Rn2/LJ2F+CxWand4gv86YkcnVS\nL4bEBPDtt99KeIsuqampidzcXBoaGk57LigoiL1797qgqs7lTu308fGhd+/eeHq2bRRG+SskejyL\n1c6aAyV8tj2fFXuLqLPYiAjw5uaxfbhmVC+S44Jl0BXhFnJzcwkICCAhIeG0/7M1NTUEBAS4qLLO\n4y7t1FpTVlZGbm4uffv2bdMxJMBFj2S12dl4pJzPt+ezbFcB1Q1Wgk2ezBzVi6tH9mJs3zC5hadw\nOw0NDa2Gt+h6lFKEhYVRUlLS5mNIgIsew27XbM2u4PPt+Xy5s4BSswU/LyPThkVzzcheTOwfjpeH\njEsu3JuEt/to789KAlx0a1prdudX8/n2fL7YUUBeZT3eHgamDonk6qRepA+OlMFWhBBuSQJcdEuH\nis18tj2fL7bnc6S0Fg+DYsrACP5w+UAuHRJFgI/culOIrmjGjBm8++67BAcHu7qULk8CXHQbOeV1\nfL4jn8+3F7C3oBqlYFzfMH4+JZHpw6IJ8fNydYlCiDPQWqO1ZunSpa4uxW1IgAu3VlzdwJc7C/hs\nez4/ZFcCkNwnmIevHsqVI2KIDPRxcYVCuMajn+9mT35187LNZsNobN/HRUN7BfLw1cN+dJv58+cT\nFxfHL3/5SwAeeeQRPDw8WL16NRUVFTQ1NfHYY48xc+ZMjh07xuWXX87YsWPJzMxk6dKlXHzxxWzZ\nsoXw8HCuvfZacnJyaGho4L777mPevHkA+Pv7c9999/HFF1/g6+vLp59+SlRUFEVFRdx1111kZ2cD\n8NJLLzFhwgT+85//8Nxzz2GxWBg7diwvvvhiu/8tugK5Yke4pR25ldz22veMfWIlj36+h4YmOw9O\nH8zaB9L5+N6JzJ3YV8JbCBeYPXs2ixcvbl5evHgxc+bM4eOPP2br1q2sXr2a3//+92itATh48CD3\n3nsvu3fvJj4+/qRjvf7662RmZrJlyxaee+45ysrKAKitrWXcuHFs376dKVOm8MorrwDwm9/8hokT\nJ7J9+3a2bt3KsGHD2Lt3L++//z7r169n27ZtGI1GFi5c2En/GheW9MCFWymuaeCpr/azZGsuYX5e\n/PqSAVwzMob+kV3/e59CdKZTe8qd9f3o5ORkiouLyc/Pp6SkhJCQEKKjo/nd737HmjVrMBgM5OXl\nUVRUBEB8fDzjxo1r9VjPPfccH3/8MQA5OTkcPHiQsLAwvLy8uOqqqwBISUlh+fLlAKxatYoXXngB\nAKPRSFBQEO+88w6ZmZlcdNFFANTX1xMZGXlB/w06iwS4cAuNVhuvrzvG86sOYrHZmTc5kV9d0l8u\nRhOiC7r++utZsmQJhYWFzJ49m4ULF1JSUkJmZiaenp4kJCQ0jxbn5+fX6jEyMjJYsWIFGzZswGQy\nkZaW1ryPp6dn81ewjEYjVqv1jLVorZkzZw5PPPFEB7fS9eQUuujStNZ8vbuQac+u4Z9f7WN8v3C+\n+d3FPDRjiIS3EF3U7NmzWbRoEUuWLOH666+nqqqKyMhIPD09Wb16NVlZWWc9RlVVFSEhIZhMJvbt\n28fGjRvPus/UqVN59dVXAcdn/lVVVUydOpUlS5ZQXFwMQHl5+Tm9vjtoc4ArpeKUUquVUnuUUruV\nUvc514cqpZYrpQ46pyHO9Uop9ZxS6pBSaodSanRHNUJ0T/sKq7n1te+5+51MvIwG3rlzDK/OSaVv\neOvv2IUQXcOwYcOoqakhNjaWmJgYbrnlFrZs2cKIESN4++23GTx48FmPMX36dKxWK0OGDGH+/Pln\nPM3e0r/+9S/Wrl3LiBEjSElJYc+ePQwdOpTHHnuMadOmkZSUxGWXXUZBQUFHNNPl2nMK3Qr8Xmu9\nVSkVAGQqpZYDtwMrtdZPKqXmA/OBB4ErgAHOx1jgJedUiJOU11p4dvkBFn6fRYCPJ49eM4xbxvbB\nwygnjIRwFzt37myeDw8PZ8OGDa1ut2vXrpOWjx071jy/bNmyVvcxm83N87NmzWLWrFkAREVFsWjR\notM+6589ezazZ88+r/rdQZsDXGtdABQ452uUUnuBWGAmkObc7C0gA0eAzwTe1o5LDzcqpYKVUjHO\n4whBk83OfzZm8ezyA9RabNw2Lp7fXjpQvr8thBCtUMcv5W/XQZRKANYAw4FsrXWwc70CKrTWwUqp\nL4AntdbrnM+tBB7UWm855VjzgHkAUVFRKYsWLWp3fa5mNpvx9/d3dRkXXHvaubPEynv7LOTXaoaF\nGbh5sDexAV2zxy0/z+6lO7UzKCiI/v37t/pcR3wP3B24WzsPHTpEVVXVSevS09MztdapZ9u33Veh\nK6X8gQ+B32qtq1sOzq611kqp83qHoLVeACwASE1N1Wlpae0t0eUyMjLoDu04m7a080iJmce+3Muq\nfcUkhJl49adDmTokskvfkEF+nt1Ld2rn3r17z/hVMXe5zWZ7uVs7fXx8SE5ObtO+7QpwpZQnjvBe\nqLX+yLm66PipcaVUDFDsXJ8HxLXYvbdzneiBquqb+PfKg7z53TF8PI38acZg5kxIwNvDfd45CyGE\nK7U5wJ2nx18D9mqtn2nx1GfAHOBJ5/TTFut/pZRahOPitSr5/Lvnsdk172/O4X++2U95nYXZqXH8\nftogIgK8XV2aEEK4lfb0wCcCtwE7lVLbnOv+hCO4Fyul7gSygBuczy0FZgCHgDpgbjteW7ihjUfK\nePTzPewtqGZMQihvXT2U4bFBri5LCCHcUnuuQl8HnOmDyqmtbK+BX7b19YT7yimv44lle1m6s5DY\nYF+evzmZK0fEdOnPuYUQoqvrmpf5im6httHK01/vZ+oz37J6Xwn3XzaQlb+/mKuSekl4C9FNHTt2\njOHDh5+2/q677mLPnj0uqKj7krHQRYez2zWfbMvjn1/to6i6kWtH9eLBKwYTE+Tr6tKE6DmWzYfC\nE4Op+NqsYGznn/zoEXDFk23a9fgQp6LjSA9cdKgfsiv4yUvfcf/i7UQH+vDhPRP43xuTJbyF6EGs\nViu33HILQ4YMYdasWdTV1ZGWlsaWLY5hP+655x5SU1MZNmwYDz/8cPN+8+fPZ+jQoSQlJfGHP/zh\njMf/4IMPGD58OCNHjmTKlCmA4y5jN954I6mpqVx33XWMHTu2+fW6K+mBiw5RWNXAgh2NfPfVd0QG\nePP09SP5SXIsBoOcKhfCJU7pKdd34vej9+/fz2uvvcbEiRO54447ePHFF096/vHHHyc0NBSbzcbU\nqVPZsWMHsbGxfPzxx+zbtw+lFJWVlWc8/t///ne+/vprYmNjm7d76aWXMJlMbNmyhaNHjzJ6dPe/\n3Yb0wEWbNTTZWLazgF+8k8mU/17NpkIrv0zvx+o/pDErpbeEtxA9VFxcHBMnTgTg1ltvZd26dSc9\nv3jxYkaPHk1ycjK7d+9mz549BAUF4ePjw5133slHH32EyWQ64/EnTpzI7bffziuvvILNZgNgzZo1\n3HrrrQAkJSWRlJR0gVrXdUgPXJwXm12z8UgZn27LY9muQmoarIT7e3PLuD4MMRZxw+Vnv8uQEKJ7\nO/Ui1ZbLR48e5emnn2bz5s2EhIRw++2309DQgIeHB5s2bWLlypUsWbKE559/nlWrVrV6/Jdffpnv\nv/+eL7/8kpSUFDIzMy9oe7oqCXBxVlprduVV8+m2PD7fkU9RdSP+3h5cPiyaa5N7MT4xDA+jgYyM\nEleXKoToArKzs9mwYQPjx4/n3XffZdKkSXz++ecAVFdX4+fnR1BQEEVFRSxbtoy0tDTMZjN1dXXM\nmDGDiRMnkpiYeMbjHz58mLFjxzJ27FiWLVtGTk4OU6ZM4d133+Wiiy5i165d7Nixo7Oa6zIS4OKM\nsspq+XRbPp9sy+NISS2eRkXaoEiuHRXL1CGR+HjKsKdCiNMNGjSIF154gTvuuIOhQ4dyzz33NAf4\nyJEjSU5OZvDgwSedaq+pqWHmzJk0NDSgteaZZ5454/H/+Mc/cvDgQbTWTJ06lZEjRzJo0CDmzp3b\nfHFcSkpKp7TVlSTAxUlKzY18sT2fT7fn80O24+KQsX1D+fnkRK4YHk2wSW7tKYQ4s4SEBPbt23fa\n+oyMjOb5N998s9V9N23adE6v8dFHH522ztfXl0WLFjXfzKS73KDmx0iAC8yNVr7ZXcin2/JZd6gU\nm10zJCaQ+VcM5pqRvegVLF8BE0KIrkYCvIeyWO2sPVjCJ9vyWb6nkIYmO7HBvtw9JZFrk2MZGOU+\nt+MTQnRPjz/+OB988MFJ666//vr/b+/eo6qs0wWOfx8uSkKDpCIK5l0JvN8wOx4lyhzrpCdtnNIi\np7O6ztHj1Dgzurq4RsvW2HQ7dszVqGU2plYey0tp52RaWSoWoHbSEU0Q1CQQVETYz/ljbwlEgnTv\n/bo3z2ctFu/77vfy/DawH37v5fcwY8aMeret3uMPVpbAGxGXS9nx3Q+s2pnH2qx8fjh1lphm4Yzr\nn8CYPvH0uzrGHv0yxlw2ZsyY0aBk3VhZAm8E/q+ghFVf5bH6q8PkFZ0mIjyEEUnuO8iHdm1FeKgN\nB2CMMYHGEniQyis6zXtfH2bVzjy+KSghNEQY2rUlj97UjRFJcUQ2tR+9McYEMvsUDyInz1SwNiuf\nlTty+SKnEIB+Vzdn5q3J3NyrDS2jmjocoTHGGG+xBB7gVJXtB39gxfZDrMnM52R5JR1bRvLIjd0Y\n3Seeq1vUPRyhMcY4obKyktDQ0Drn61JRUUFYmKWtc+ydCFD5xad5JyOPlTtyyfn+JJFNQrmlV1tu\nH5BA//YxVm/bGOOYN954gxdffJHy8nJSUlJ4+eWXiY6O5v7772fjxo3MmzePiRMnMn78eDZs2MC0\nadNITEzkgQce4NSpU3Tu3JmFCxcSExPD8OHD6dOnD1u2bOGOO+7gkUcecbp5lw1L4AHkTEUlG3Yf\nYcX2XDbvPYZL3YOsPDAsZf0AAA9DSURBVJzahVE942jWxH6cxhi3Z758hm8KfxxQpaG93J+SeFUi\nfxj0h59cZ8+ePbz11lt8+umnhIeH89BDD7F06VJOnjxJSkoKzz77bNW6LVq0ICMjA3AXIHnppZcY\nNmwYjz/+ODNnzuT5558HoLy8POhLg14M+8S/zKkquw6fYMX2Q6z66jDFp8/SNjqCh1O7MK5/Au1b\nRDodojHGVPnoo4/YsWMHAwcOBNx1umNjYwkNDWXs2LE11h0/fjwAxcXFFBUVMWzYMADS09O5/fbb\na61narIEfpk6XnqGVV8dZsX2Q3xTUEKTsBBGJsdx+4AEhnRuSag9r22M+Qnn95RL/FQPXFVJT0/n\n6aefrrF87ty5tc4AREY2rAPS0PUaG0vgl5GKShebvj3Giu25fPTNEc5WKr0TovnzmB7c2qst0c3C\nnQ7RGGN+UlpaGqNHj2bq1KnExsZSWFhISUnJT24THR1NTEwMmzdvZujQoSxZsqSqN27qZgn8MrDv\naAkrtufyzs48jpWcoWVUE+4Z0oFx/dvRPc6GNDXGBI6kpCRmzZrFiBEjcLlchIeHM2/evHq3e+21\n16puYuvUqROLFi3yQ7SBzRK4Q06UneX9r/NZseMQO78rIixESE2M5fb+CaQmxtroaMaYgDV+/Pha\n161LS0trzB84cKDGfJ8+fdi6dWutfTWGMc0vliVwP3K5lK37j7NiRy7rsvMpO+uiW+soZoy6hjF9\n42l1pQ20YowxpmEsgfvBsVMuntvwLW9n5JL7w2mujAhjbL8EfjWgHb0Sou2ZbWOMMT+bJXAfOVpS\nxge7jrAm8zBb959GZC//1KUlv7+pOzclxxERfmnPYxpjjGncLIF7UX7xadZnF7Auq4BtBwtRhU6t\nIvnXLuE8Om4o8c2vcDpEY4wxQcIS+CU6VHiKddn5rMsuYOd3RQAkxl3JlLSujOrZhq6xUWzatMmS\ntzHGGK+yBH4R9h8rZV12AeuzC8jKKwagR/wv+P1N3RnZI47OraIcjtAYY0ywswTeQHuPlLA2q4B1\n2fl8U+AelKBPu+ZMH5XIyOQ2VvXLGGOMX1kCr4Oqsjv/BOuzC1iblc8/jp1EBAa0j+HxW5IY2SOO\ntnZa3BhjjEMsgVejqmTmFrM2O5/12QUcPH6KEIHBnVpwz5AO3JQcR+wvIpwO0xhjAprVA/eORv9O\nuFzKzkM/sDbLfU07r+g0YSHCkC4teWBYZ0YktaZFlA2wYowJLAVPPcWZPT+WE62orKTwEsuJNr0m\nkbjp039ynQvVAg8NDSUqKsrr9cC//PJLpkyZQllZGVdccQWLFi2ibdu27Nq1i0mTJlFeXo7L5eLt\nt9+ma9euNeJ88MEH2bZtG6dPn2bcuHHMnDmzVltefPFF5s+fT1hYGElJSSxbtownn3ySqKgoHn30\nUQB69OjB+++/D8DIkSMZPHgwn332GQMHDmTSpEk88cQTHD16lKVLlzJo0KBLev/P1ygTeKVL2Xag\nkHVZ+azfVcCRE2doEhrC0K4tmXpjN264JpbmzZo4HaYxxgSUumqB33333T6pB56YmMjmzZsJCwtj\n48aNTJ8+ncWLFzN//nymTJnChAkTKC8vp7Kysta2s2fP5qqrrqKyspK0tDQyMzPp1atXjXXmzJlD\nTk4OTZs2paioqN7279u3jxUrVrBw4UIGDhzIm2++yZYtW1i9ejVPPfUUq1at+lnvZ338nsBFZCTw\nAhAKvKqqc/xx3IpKF1v3F7I2O58PdxXwfWk5TcNCGN69FaN6tuH6xFiujLBqX8aY4HB+T9kf5UTr\nqgUO+KQeeHFxMenp6ezduxcR4ezZswBce+21zJ49m9zcXG677bZavW+A5cuXs2DBAioqKsjPz2f3\n7t21EnivXr2YMGECY8aMYcyYMfW2v2PHjvTs2ROA5ORk0tLSEBF69uxZa+x3b/BrAheRUGAecCOQ\nC2wTkdWqutvXxz51tpJJi78kPDSE1MRYRvVow/DurYhs2ihPQhhjjNfVVQscICIiwuv1wB977DFS\nU1N59913OXDgAMOHDwfgzjvvJCUlhTVr1jBq1CheeeUVrr/++qrtcnJymDt3Ltu2bSMmJoZ77rmH\nsrKyWvtfs2YNn3zyCe+99x6zZ88mKyuLsLAwXC5X1TrVt2va9MfLrSEhIVXzISEhVFRUNKitP4e/\nS14NAvap6n5VLQeWAaP9ceBfRISz7L7BZDx2I/Pu7MfNvdpY8jbGGC9KS0tj5cqVHD16FIDCwkIO\nHjxY73bV64EDDa4HXlxcTHx8PACLFy+uWr5//346derE5MmTGT16NJmZmTW2O3HiBJGRkURHR3Pk\nyBHWrVtXa98ul4tDhw6RmprKM888Q3FxMaWlpXTo0KHqtH9GRgY5OTn1xukr/s5g8cChavO5QIq/\nDt6//VX+OpQxxjQ6ddUCb9++fb3bXkw98GnTppGens6sWbO4+eabq5YvX76cJUuWEB4eTlxcHNPP\nu5zQu3dv+vbtS2JiIu3ateO6666rte/KykomTpxIcXExqsrkyZNp3rw5Y8eO5fXXXyc5OZmUlBS6\ndevWgHfGN0RV/XcwkXHASFX9N8/8XUCKqv622jr3AfcBtG7duv+yZcv8Fp+vlJaWEhUV/KOzWTuD\ni7Uz8ERHR9OlS5cLvtbQR7UCXaC1c9++fRQXF9dYlpqaukNVB9S3rb974HlAu2rzCZ5lVVR1AbAA\nYMCAAXrumkYg+/jjjwmGdtTH2hlcrJ2BZ8+ePXXeqOaPm9guB4HWzoiICPr27XtR2/r7Gvg2oKuI\ndBSRJsCvgdV+jsEYY4wJeH7tgatqhYj8FvgA92NkC1V1lz9jMMaYYKaqiIjTYZgGuNRL2H6/DVtV\n1wJr/X1cY4wJdhERERw/fpwWLVpYEr/MqSrHjx8nIuLih+e256iMMSZIJCQkkJuby7Fjx2q9VlZW\ndknJIlAEUjsjIiJISEi46O0tgRtjTJAIDw+nY8eOF3zt448/vuibpQJJY2kn+P8mNmOMMcZ4gSVw\nY4wxJgBZAjfGGGMCkF9HYvu5ROQYUP9Aupe/lsD3TgfhB9bO4GLtDC7WzsDRXlVb1bfSZZ3Ag4WI\nbG/IsHiBztoZXKydwcXaGXzsFLoxxhgTgCyBG2OMMQHIErh/LHA6AD+xdgYXa2dwsXYGGbsGbowx\nxgQg64EbY4wxAcgSuDHGGBOALIH7iIi0E5H/FZHdIrJLRKY4HZMviUioiOwUkfedjsVXRKS5iKwU\nkW9EZI+IXOt0TL4gIlM9v7PZIvJ3EQmMyhD1EJGFInJURLKrLbtKRDaIyF7P9xgnY/SGOtr5F8/v\nbaaIvCsizZ2M0Rsu1M5qrz0iIioiLZ2IzV8sgftOBfCIqiYBg4GHRSTJ4Zh8aQqwx+kgfOwFYL2q\nJgK9CcL2ikg8MBkYoKo9gFDg185G5TWLgZHnLfsj8JGqdgU+8swHusXUbucGoIeq9gK+Bf7k76B8\nYDG124mItANGAN/5OyB/swTuI6qar6oZnukS3B/28c5G5RsikgDcDLzqdCy+IiLRwD8DfwNQ1XJV\nLXI2Kp8JA64QkTCgGXDY4Xi8QlU/AQrPWzwaeM0z/Rowxq9B+cCF2qmqH6pqhWd2K3DxNSwvE3X8\nPAGeA6YBQX+HtiVwPxCRDkBf4AtnI/GZ53H/wbicDsSHOgLHgEWeSwWvikik00F5m6rmAXNx917y\ngWJV/dDZqHyqtarme6YLgNZOBuMnvwHWOR2EL4jIaCBPVb92OhZ/sATuYyISBbwN/IeqnnA6Hm8T\nkVuAo6q6w+lYfCwM6Af8l6r2BU4SHKdba/BcAx6N+x+WtkCkiEx0Nir/UPcztUHdaxORGbgv7y11\nOhZvE5FmwHTgcadj8RdL4D4kIuG4k/dSVX3H6Xh85DrgVhE5ACwDrheRN5wNySdygVxVPXcWZSXu\nhB5sbgByVPWYqp4F3gGGOByTLx0RkTYAnu9HHY7HZ0TkHuAWYIIG5wAgnXH/4/m15/MoAcgQkThH\no/IhS+A+IiKC+3rpHlX9q9Px+Iqq/klVE1S1A+6bnf5HVYOux6aqBcAhEenuWZQG7HYwJF/5Dhgs\nIs08v8NpBOHNetWsBtI90+nAfzsYi8+IyEjcl7luVdVTTsfjC6qapaqxqtrB83mUC/Tz/O0GJUvg\nvnMdcBfuHulXnq9RTgdlLsm/A0tFJBPoAzzlcDxe5znDsBLIALJwf0YExdCUIvJ34HOgu4jkisi9\nwBzgRhHZi/vswxwnY/SGOtr5n8CVwAbPZ9F8R4P0gjra2ajYUKrGGGNMALIeuDHGGBOALIEbY4wx\nAcgSuDHGGBOALIEbY4wxAcgSuDHGGBOALIEbEyBEpEW1RxILRCSv2nwTHx0zTEQuesx3EfnduWpm\nl7ovY0xN9hiZMQFIRJ4ESlV17nnLBffftVfGpfcUNPleVS+q/KSI5OKuglV0qfsyxtRkPXBjApyI\ndPHUnV8K7ALaiMgvReRzEckQkbfOFV4RkYEisklEdojIOhGpVbxDRDqLyBcikgXMPO+1P4rIl566\n0o9XO/4uEVnmqZO+XESuEJGpQCywWUQ2VtvHHBH52hNfrA/fGmOCmiVwY4JDIvCcp/78WdyFVtJU\ntR+QCUwRkaa4a5qPVdX+wBvAny+wr5eAF1S1J9XGBveMJHg1kIJ7JLohInJunPQk4HlVvQYoA+5X\n1ec82w9V1Rs860UDm1S1N+5RtH7jtXfAmEYmzOkAjDFe8Q9V3e6ZHoI7oX7mPqNOE2ALcA2QDGz0\nLA/FPV70+a4F/sUzvYQfe+EjgF8COz3zUUA33Ek6R1W3epa/AdyHu8zs+U6r6rlSljuAoT+rlcaY\nKpbAjQkOJ6tNC7BeVe+qvoKI9AUyVbUhSfNCN8cIMEtV/3befrtcYP26bq4przZdiX0GGXPR7BS6\nMcHnM2CYiHQCEJFIEemKu3pavIgM8ixvIiLJF9j+c+BXnukJ1ZZ/ANxb7Xp6goi09LzWUUQGeqbv\nxN3jByjBXUTDGONllsCNCTKqegS4F3hLRL7GndC7qeoZYBzwV09FtZ24r2efbzIw1bNO1U1uqroW\nd6WyrZ4b3JbjPo0O7pKjvxORPUAzfqxgtgD3Kfuqm9iMMd5hj5EZYy6J5xT6SlXt43QsxjQm1gM3\nxhhjApD1wI0xxpgAZD1wY4wxJgBZAjfGGGMCkCVwY4wxJgBZAjfGGGMCkCVwY4wxJgD9P7hSansX\nXfr2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "xr8dTiFjHLp3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Композиции алгоритмов\n",
        "\n",
        "Несмотря на описанный выше недостаток решающих деревьев, объединение их в композиции позволяет существенно улучшить качество предсказания. Рассмотрим несколько способов построения композиций.\n",
        "\n",
        "### Bagging + RSM\n",
        "\n",
        "![](https://sites.google.com/site/rajhansgondane2506/_/rsrc/1467898300734/publications/rrftrain.jpg?height=215&width=320)\n",
        "\n",
        "Один из способов объединения алгоритмов в композиции — обучение каждого отдельного алгоритма на некоторой подвыборке из исходной выборки ([bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating)) и подмножестве исходных признаков ([RSM](https://en.wikipedia.org/wiki/Random_subspace_method)). В sklearn этот тип композиции реализован в классе [BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html) (для случая регресии). Подобный подход также есть в реализации [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
      ]
    },
    {
      "metadata": {
        "id": "BBX0cb2_HLp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Градиентный бустинг\n",
        "\n",
        "В случае бустинга композиция алгоритмов строится последовательно. Каждый следующий базовый алгоритм акцентируется на тех объектах, на которых обученная ранее композиция допускала ошибку.\n",
        "\n",
        "На данный момент одной из самых широко распространенных реализаций бустинга является библиотека [XGBoost](https://github.com/dmlc/xgboost). В ней большое внимание уделяется регуляризации и скорости, нежели в других реализациях бустинга (например,  [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) из sklearn). Кроме того, XGBoost позволяет оптимизировать различные функции потерь, а также более гибок, засчет большого числа параметров."
      ]
    },
    {
      "metadata": {
        "id": "dcMOYmLPHLp9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "XGBoost строит композицию из $K$ базовых алгоритмов $b_k$:\n",
        "\n",
        "$$ \\hat{y}_i = \\hat{y}_i^{K} = \\sum_{k=1}^{K} b_k(x_i) = \\hat{y}_i^{\\left(K - 1\\right)} + b_K(x_i), $$\n",
        "\n",
        "минимизируя следующий функционал:\n",
        "\n",
        "$$ Obj = \\sum_{i=1}^N \\mathcal{L}(y_i, \\hat{y}_i ) + \\sum_{k=1}^{K} \\Omega(b_k),$$\n",
        "\n",
        "где\n",
        " - $N$ — размер обучающей выборки;\n",
        " - $x_i, y_i, \\hat{y}_i$ — i-ый объект, правильный ответ и предсказание модели для него;\n",
        " - $\\hat{y}_i^{t}$ — предсказание композиции из $t$ уже обученных базовых алгоритмов для i-го объекта;\n",
        " - $\\Omega$ — регуляризатор;\n",
        " - $\\mathcal{L}(y_i, \\hat{y}_i)$ — функция потерь.\n",
        "\n",
        "Функционал, оптимизируемый на $t$-ой итерации:\n",
        "\n",
        "$$ Obj^{(t)} = \\sum_{i=1}^N \\mathcal{L}\\left(y_i, \\hat{y}_i^{(t-1)} + b_t(x_i)\\right) + \\Omega(b_t).$$"
      ]
    },
    {
      "metadata": {
        "id": "vY7GoayzHLp_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В XGBoost реализовано несколько различных функций потерь, что позволяет решать задачи классификации (бинарной и мультиклассовой), регрессии и ранжирования. Вот некоторые из них:\n",
        "\n",
        "- reg:linear — линейная регрессия\n",
        "- reg:logistic — логистическая регрессия\n",
        "- binary:logistic — логистическая регрессия\n",
        "- multi:softmax — softmax функция потерь для многоклассовой классификации\n",
        "- rank:pairwise — минимизация pairwise-функции потерь для задачи ранжирования"
      ]
    },
    {
      "metadata": {
        "id": "-tUqM0AJHLqC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(1 балл) Задание 3.** Проведите аналогичный эксперимент с bias-variance разложением для градиентного бустинга для количество алгоритмов 1, 5, 10, 25 и 50, используя в качестве базовых алгоритмов решающие деревья. Обратите внимание, что данная библиотека имеет два интерфейса (стандартный и аналог sklearn), названия параметров в которых могут отличаться."
      ]
    },
    {
      "metadata": {
        "id": "t04Eb_4YHLqE",
        "colab_type": "code",
        "colab": {},
        "outputId": "007f061e-36c4-4843-f0db-1794b0ede32c"
      },
      "cell_type": "code",
      "source": [
        "all_predictions = []\n",
        "n_estimators = [1, 5, 10, 25, 50]\n",
        "for est in n_estimators:\n",
        "    predictions = []\n",
        "    for _ in tqdm(range(100)):\n",
        "        X_subsample, y_subsample = subsample(X_train, y_train)\n",
        "        clf = XGBRegressor(n_estimators=est)\n",
        "        clf.fit(X_subsample, y_subsample)\n",
        "        predictions.append(clf.predict(X_test))\n",
        "    all_predictions.append(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n",
            "100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n",
            "100%|██████████| 100/100 [02:24<00:00,  1.45s/it]\n",
            "100%|██████████| 100/100 [04:33<00:00,  2.73s/it]\n",
            "100%|██████████| 100/100 [08:33<00:00,  5.13s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5emoHztHLqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "variances = [np.mean([mean_squared_error(np.mean(predictions, axis=0), pred) \n",
        "                      for pred in predictions]) for predictions in all_predictions]\n",
        "\n",
        "biases = [mean_squared_error(y_test, np.mean(predictions, axis=0)) for predictions in all_predictions]\n",
        "\n",
        "errors = [np.mean([mean_squared_error(y_test, prediction) \n",
        "                  for prediction in predictions]) for predictions in all_predictions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ej7Y6SWHLqS",
        "colab_type": "code",
        "colab": {},
        "outputId": "9bd73be4-8405-4ed3-ef96-4cb08386726e"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(n_estimators, variances, label='variance')\n",
        "plt.plot(n_estimators, biases, label='bias_sq')\n",
        "plt.plot(n_estimators, errors, label='error')\n",
        "plt.xlabel('Number of estimators')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFACAYAAABDZi6TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2UkMOcDiHLqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(0.5 балла) Задание 4.** Отличаются ли графики в рассмотренных моделях (решающее дерево, градиентный бустинг на решающих деревьях)  между собой? На какую компоненту из разложения ошибки влияет объединение алгоритмов в рассмотренный тип композиции? Поясните свой ответ."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "KiSL2pa-HLqg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Да, графики очень отличаются. Видно, что дисперсия крайне мала по сравнению с прошлым графиком. То есть данный тип композиции уменьшает дисперсию и не даёт ей сильно расти с ростом estimators. Уменьшение дисперсии, видимо, следует из того, что каждый следующий базовый алгоритм акцентируется на тех объектах, на которых обученная ранее композиция допускала ошибку."
      ]
    },
    {
      "metadata": {
        "id": "9NfnuitfHLqj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Стекинг\n",
        "![](https://4.bp.blogspot.com/-hCxAb57kzDQ/VuMgHy3hAhI/AAAAAAAAAVk/djmL9IHv5QkLWeudjE50qDoCTbiUrTetA/s1600/Stacking.jpg)\n",
        "\n",
        "[Stacking](https://en.wikipedia.org/wiki/Ensemble_learning#Stacking) — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle. Подход использует понятие *базовых классификаторов*, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также *мета-классификатора*, использующего предсказания базовых классификаторов как факторы. \n",
        "\n",
        "Загрузите [датасет](https://archive.ics.uci.edu/ml/datasets/covertype). В тренировочных целях предлагается вместо задачи мультиклассификации решать задачу обычной бинарной классификации — научиться отличать **Spruce-Fir** (значение целевой переменной — 1) от **Lodgepole Pine** (значение целевой переменной — 2). Разделите выборку на обучение и тест в соотношении 50/50. В качестве метрики используйте [accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)."
      ]
    },
    {
      "metadata": {
        "id": "lg9TEJ7IHLqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(1 балл) Задание 5.** Использование мета-классификатора подразумевает получение предсказаний от базовых классификаторов для тех объектов обучающей выборки, на которых мета-классификатор будет обучаться. В свою очередь базовые классификаторы тоже должны быть обучены на некоторой выборке. Чтобы избежать переобучения, обучающее множество делится на $n$ фолдов, $(n-1)$ из которых используются для обучения базовых классификаторов, а $n$-ый — для предсказания (вычисления мета-фактора).\n",
        "\n",
        "Для получения мета-факторов для тестовых данных базовые классификаторы могут быть обучены на всем обучающем множестве, поскольку проблема переобучения здесь не возникает. Другими словами, если мы хотим посчитать факторы для тестового множества, мы можем спокойно использовать обучающее множество для тренировки базовых классификаторов. Если же мы хотим посчитать факторы для обучающего множества, то необходимо следить, чтобы классификатор не предсказывал для тех объектов, на которых обучался.\n",
        "\n",
        "Мета-классификатор может быть обучен как на множестве исходных факторов, дополненным мета-факторами, так и исключительно на множестве мета-факторов. Выбор зависит от решаемой задачи.\n",
        "\n",
        "Напишите функцию, которая получает на вход классификатор, обучающую и тестовые выборки, а также параметры [кросс-валидатора](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) и возвращающую значения мета-фактора для обучающего и тестового множеств"
      ]
    },
    {
      "metadata": {
        "id": "V-HRRO8VH-x8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "7e6eba31-20bb-4429-f860-9d614ff5deef"
      },
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz&ts=1489637334&use_mirror=excellmedia"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-21 14:48:42--  https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11240707 (11M) [application/x-gzip]\n",
            "Saving to: ‘covtype.data.gz’\n",
            "\n",
            "covtype.data.gz     100%[===================>]  10.72M  14.4MB/s    in 0.7s    \n",
            "\n",
            "2018-10-21 14:48:43 (14.4 MB/s) - ‘covtype.data.gz’ saved [11240707/11240707]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x7-2qdPLHLqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "de2fb744-bd3a-423a-a5f5-c200266fb32e"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('covtype.data.gz', header=None)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2    3    4     5    6    7    8     9  ...  45  46  47  48  49  \\\n",
              "0  2596   51   3  258    0   510  221  232  148  6279 ...   0   0   0   0   0   \n",
              "1  2590   56   2  212   -6   390  220  235  151  6225 ...   0   0   0   0   0   \n",
              "2  2804  139   9  268   65  3180  234  238  135  6121 ...   0   0   0   0   0   \n",
              "3  2785  155  18  242  118  3090  238  238  122  6211 ...   0   0   0   0   0   \n",
              "4  2595   45   2  153   -1   391  220  234  150  6172 ...   0   0   0   0   0   \n",
              "\n",
              "   50  51  52  53  54  \n",
              "0   0   0   0   0   5  \n",
              "1   0   0   0   0   5  \n",
              "2   0   0   0   0   2  \n",
              "3   0   0   0   0   2  \n",
              "4   0   0   0   0   5  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "fIpJywRBHLrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "0a71e866-7ec3-48ae-8af6-e760e820e80e"
      },
      "cell_type": "code",
      "source": [
        "binary_class_df = df[df[54] < 3]\n",
        "binary_class_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2579</td>\n",
              "      <td>132</td>\n",
              "      <td>6</td>\n",
              "      <td>300</td>\n",
              "      <td>-15</td>\n",
              "      <td>67</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>140</td>\n",
              "      <td>6031</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2886</td>\n",
              "      <td>151</td>\n",
              "      <td>11</td>\n",
              "      <td>371</td>\n",
              "      <td>26</td>\n",
              "      <td>5253</td>\n",
              "      <td>234</td>\n",
              "      <td>240</td>\n",
              "      <td>136</td>\n",
              "      <td>4051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2742</td>\n",
              "      <td>134</td>\n",
              "      <td>22</td>\n",
              "      <td>150</td>\n",
              "      <td>69</td>\n",
              "      <td>3215</td>\n",
              "      <td>248</td>\n",
              "      <td>224</td>\n",
              "      <td>92</td>\n",
              "      <td>6091</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1   2    3    4     5    6    7    8     9  ...  45  46  47  48  \\\n",
              "2   2804  139   9  268   65  3180  234  238  135  6121 ...   0   0   0   0   \n",
              "3   2785  155  18  242  118  3090  238  238  122  6211 ...   0   0   0   0   \n",
              "5   2579  132   6  300  -15    67  230  237  140  6031 ...   0   0   0   0   \n",
              "11  2886  151  11  371   26  5253  234  240  136  4051 ...   0   0   0   0   \n",
              "12  2742  134  22  150   69  3215  248  224   92  6091 ...   0   0   0   0   \n",
              "\n",
              "    49  50  51  52  53  54  \n",
              "2    0   0   0   0   0   2  \n",
              "3    0   0   0   0   0   2  \n",
              "5    0   0   0   0   0   2  \n",
              "11   0   0   0   0   0   2  \n",
              "12   0   0   0   0   0   2  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "DRHGJZmJHLrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(binary_class_df)[:, :54], \n",
        "                                                    np.array(binary_class_df[54]) - 1, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhxRq58SHLrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv, *args, **kwargs):\n",
        "    clf.fit(X_train, y_train)\n",
        "    if hasattr(clf, 'predict_proba'):\n",
        "        meta_feature_test = clf.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        meta_feature_test = clf.predict(X_test)\n",
        "\n",
        "    meta_feature_train = np.zeros(y_train.shape)\n",
        "    for train_ind, test_ind in cv.split(X_train):\n",
        "        clf_clone = sklearn.base.clone(clf)\n",
        "        clf_clone.fit(X_train[train_ind], y_train[train_ind])\n",
        "\n",
        "        if hasattr(clf_clone, 'predict_proba'):\n",
        "            meta_feature_train[test_ind] = clf_clone.predict_proba(X_train[test_ind])[:, 1]\n",
        "        else:\n",
        "            meta_feature_train[test_ind] = clf_clone.predict(X_train[test_ind])\n",
        "    return meta_feature_train, meta_feature_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Beb55LVVHLrh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Поэкспериментируйте со стекингом, ответьте на вопросы и обоснуйте наблюдения:\n",
        "  - **(1 балл) Задание 6.** Обучите различные известные вам модели машинного обучения и сделайте из них стекинг-композицию. \n",
        "  \n",
        "  Базовые алгоритмы могут отличаться друг от друга:\n",
        "    - моделью машинного обучения,\n",
        "    - гиперпараметрами (например, различные функции потерь или глубины деревьев),\n",
        "    - набором факторов,\n",
        "    - типом модели: для данной задачи можно использовать как классификаторы, так и регрессоры.\n",
        "  \n",
        "  Обратите внимание, что бинарные мета-факторы дают меньше полезного сигнала мета-классификатору, чем числовые, поэтому базовым классификаторам лучше возвращать вероятность/числовую функцию, чем метки классов.\n",
        "  - **(1 балл) Задание 7.** Обучите мета-классификатор на различных наборах факторов:\n",
        "    - исходные факторы,\n",
        "    - исходные факторы + мета-факторы,\n",
        "    - мета-факторы.\n",
        "    \n",
        "    Имеет ли смысл добавлять исходные факторы в мета-классификатор, если базовые классификаторы уже обучены на этом наборе? Удается ли добиться улучшения качества за счет стекинга? Какие классификаторы лучше сочетаются друг с другом в такой композиции?\n",
        "  - **(0.5 балла) Задание 8.** Попробуйте разные размеры фолда при подсчете мета-факторов. Влияет ли размер на качество?\n",
        "  - **(0.5 балла) Задание 9.** Зафиксируйте некоторый набор базовых классификаторов. Обучите поверх них линейную модель и сравните ее с мета-классификатором, который считает среднее по всем метафакторам. Дает ли преимущество линейная модель? О чем говорят коэффициенты линейной модели в данном случае?\n"
      ]
    },
    {
      "metadata": {
        "id": "CFKzh3teHLrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_meta_dataset(classifiers, X_train, X_test, y_train, cv):\n",
        "    train_data, test_data = [], []\n",
        "    for clf in tqdm(classifiers):\n",
        "        meta_feature_train, meta_feature_test = compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
        "        train_data.append(meta_feature_train)\n",
        "        test_data.append(meta_feature_test)\n",
        "    return np.array(train_data).T, np.array(test_data).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5F7Jx1VyHLrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "ef4333f4-7e39-468c-ce18-4d310148233b"
      },
      "cell_type": "code",
      "source": [
        "classifiers = [KNeighborsClassifier(), \n",
        "               LinearRegression(n_jobs=-1),\n",
        "               RandomForestClassifier(n_jobs=-1), \n",
        "               LinearSVC()]\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "train_data, test_data = create_meta_dataset(classifiers, X_train, X_test, y_train, cv)\n",
        "train_data[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 1/4 [01:05<03:17, 65.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 2/4 [01:12<01:36, 48.09s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 3/4 [01:39<00:41, 41.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 4/4 [07:21<00:00, 132.00s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.17939853, 0.        , 1.        ],\n",
              "       [0.6       , 0.45468365, 0.9       , 1.        ],\n",
              "       [0.        , 0.54343531, 0.3       , 1.        ],\n",
              "       [1.        , 0.51167287, 1.        , 1.        ],\n",
              "       [1.        , 0.35011406, 1.        , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "hGaCnjM9QgTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "8668ed71-eb51-41ae-ac2e-a1a68b69c888"
      },
      "cell_type": "code",
      "source": [
        "classifiers = [KNeighborsClassifier(n_neighbors=10), \n",
        "               KNeighborsClassifier(n_neighbors=15),\n",
        "               DecisionTreeClassifier(max_depth=15), \n",
        "               DecisionTreeClassifier(max_depth=20)]\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "train_data_t_and_n, test_data_t_and_n = create_meta_dataset(classifiers, X_train, X_test, y_train, cv)\n",
        "train_data_t_and_n[:5]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▌       | 1/4 [01:17<03:52, 77.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 2/4 [02:59<02:49, 84.86s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▌  | 3/4 [03:17<01:04, 64.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 4/4 [03:37<00:00, 51.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.4       , 0.66666667, 0.94626866, 1.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [1.        , 1.        , 1.        , 1.        ],\n",
              "       [1.        , 1.        , 1.        , 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "NsiTvlG_I09R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "9ba09950-5053-40be-95e3-cf39f12bb636"
      },
      "cell_type": "code",
      "source": [
        "classifiers = [\n",
        "    LinearSVC(),\n",
        "    KNeighborsClassifier(3, n_jobs=-1),\n",
        "    XGBClassifier(n_estimators=10),\n",
        "    RandomForestClassifier(max_depth=10, n_estimators=20, n_jobs=-1)\n",
        "]\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True)\n",
        "train_data_last, test_data_last = create_meta_dataset(classifiers, X_train, X_test, y_train, cv)\n",
        "train_data_last[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [06:01<00:00, 112.68s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.27540949, 0.14551586],\n",
              "       [1.        , 1.        , 0.68730044, 0.731502  ],\n",
              "       [1.        , 1.        , 0.35879132, 0.46998557],\n",
              "       [1.        , 0.        , 0.36778948, 0.22789211],\n",
              "       [0.        , 0.        , 0.59374022, 0.48141555]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "-oSFRdwQHLrv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сделали стекинг-композиции, посмотрим, насколько это было удачно."
      ]
    },
    {
      "metadata": {
        "id": "KpipC53nHLry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_accuracy_scores(classifiers, X_train, X_test, y_train, y_test):\n",
        "    classifiers = [sklearn.base.clone(clf) for clf in classifiers]\n",
        "    names = [clf.__class__.__name__ for clf in classifiers]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        clf.fit(X_train, y_train)\n",
        "    scores = [accuracy_score(y_test, np.rint(clf.predict(X_test))) for clf in classifiers]\n",
        "     \n",
        "    result = {}\n",
        "    for name, score in zip(names, scores):\n",
        "        result[name] = score\n",
        "    return result\n",
        "\n",
        "\n",
        "def try_diffirent_feature_compositions(meta_classifiers, \n",
        "                                       X_train, X_test, \n",
        "                                       train_data_meta, test_data_meta, \n",
        "                                       y_train, y_test):\n",
        "    result = {}\n",
        "    result[\"Only meta-features\"] = get_accuracy_scores(meta_classifiers, train_data_meta, test_data_meta, y_train, y_test)\n",
        "    result[\"Only initial features\"] = get_accuracy_scores(meta_classifiers, X_train, X_test, y_train, y_test)\n",
        "    result[\"Meta features plus initial features\"] = get_accuracy_scores(meta_classifiers, \\\n",
        "                                                        np.concatenate((X_train, train_data_meta), axis=1), \\\n",
        "                                                        np.concatenate((X_test, test_data_meta), axis=1), y_train, y_test)\n",
        "    return pd.DataFrame(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8soa1UpoUCa2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "meta_classifiers = [KNeighborsClassifier(), \n",
        "                    LinearRegression(n_jobs=-1),\n",
        "                    RandomForestClassifier(n_jobs=-1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3_TFfBeUFcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f8988af7-3172-4d70-ecb7-c9a433426e28"
      },
      "cell_type": "code",
      "source": [
        "%time try_diffirent_feature_compositions(meta_classifiers, X_train, X_test, train_data, test_data, y_train, y_test)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 53s, sys: 719 ms, total: 1min 54s\n",
            "Wall time: 1min 39s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Meta features plus initial features</th>\n",
              "      <th>Only initial features</th>\n",
              "      <th>Only meta-features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.966696</td>\n",
              "      <td>0.966696</td>\n",
              "      <td>0.967117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.969839</td>\n",
              "      <td>0.775725</td>\n",
              "      <td>0.969734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.970154</td>\n",
              "      <td>0.941487</td>\n",
              "      <td>0.959923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Meta features plus initial features  \\\n",
              "KNeighborsClassifier                               0.966696   \n",
              "LinearRegression                                   0.969839   \n",
              "RandomForestClassifier                             0.970154   \n",
              "\n",
              "                        Only initial features  Only meta-features  \n",
              "KNeighborsClassifier                 0.966696            0.967117  \n",
              "LinearRegression                     0.775725            0.969734  \n",
              "RandomForestClassifier               0.941487            0.959923  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "47Z5QtJ2WinI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "77ac2a15-ea24-4144-bae9-1484c2362697"
      },
      "cell_type": "code",
      "source": [
        "%time try_diffirent_feature_compositions(meta_classifiers, X_train, X_test, train_data_t_and_n, test_data_t_and_n, y_train, y_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 8s, sys: 626 ms, total: 2min 9s\n",
            "Wall time: 1min 56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Meta features plus initial features</th>\n",
              "      <th>Only initial features</th>\n",
              "      <th>Only meta-features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.96670</td>\n",
              "      <td>0.966696</td>\n",
              "      <td>0.959353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.96437</td>\n",
              "      <td>0.775725</td>\n",
              "      <td>0.964168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.96462</td>\n",
              "      <td>0.942186</td>\n",
              "      <td>0.956101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Meta features plus initial features  \\\n",
              "KNeighborsClassifier                                0.96670   \n",
              "LinearRegression                                    0.96437   \n",
              "RandomForestClassifier                              0.96462   \n",
              "\n",
              "                        Only initial features  Only meta-features  \n",
              "KNeighborsClassifier                 0.966696            0.959353  \n",
              "LinearRegression                     0.775725            0.964168  \n",
              "RandomForestClassifier               0.942186            0.956101  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "jJuO2IzNKXl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "fe233eb8-25ce-4bb8-f7e7-00d5e3ae24fb"
      },
      "cell_type": "code",
      "source": [
        "%time try_diffirent_feature_compositions(meta_classifiers, X_train, X_test, train_data_last, test_data_last, y_train, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 56s, sys: 805 ms, total: 1min 56s\n",
            "Wall time: 1min 42s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Meta features plus initial features</th>\n",
              "      <th>Only initial features</th>\n",
              "      <th>Only meta-features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.967403</td>\n",
              "      <td>0.967403</td>\n",
              "      <td>0.965339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.969799</td>\n",
              "      <td>0.776472</td>\n",
              "      <td>0.969799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.969245</td>\n",
              "      <td>0.943931</td>\n",
              "      <td>0.963158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Meta features plus initial features  \\\n",
              "KNeighborsClassifier                               0.967403   \n",
              "LinearRegression                                   0.969799   \n",
              "RandomForestClassifier                             0.969245   \n",
              "\n",
              "                        Only initial features  Only meta-features  \n",
              "KNeighborsClassifier                 0.967403            0.965339  \n",
              "LinearRegression                     0.776472            0.969799  \n",
              "RandomForestClassifier               0.943931            0.963158  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "3HD2kTKid6qi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Имеет ли смысл добавлять исходные факторы в мета-классификатор, если базовые классификаторы уже обучены на этом наборе? Удается ли добиться улучшения качества за счет стекинга? Какие классификаторы лучше сочетаются друг с другом в такой композиции?**\n",
        "\n",
        "По результатам выше видно, что смесь исходных факторов и метафакторов даёт повышение качества.  Единственным исключением был KNN в самом первом случае.\n",
        "\n",
        "Лучшее качество показало следующее сочетание классификаторов:\n",
        "1. KNeighborsClassifier(), \n",
        "2. LinearRegression(n_jobs=-1),\n",
        "3. RandomForestClassifier(n_jobs=-1), \n",
        "4. LinearSVC()\n",
        "\n",
        "Скорее всего, этот результат достигается за счёт совершенно различной природы каждого из приведённых классификаторов.\n",
        "\n",
        "Попробуем увеличить число фолдов. Для генерации мета-фичей возьмём первый набор классификаторов."
      ]
    },
    {
      "metadata": {
        "id": "9iHEbBluQWKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "0804aa97-b57f-48e1-b48b-227a557fb2bc"
      },
      "cell_type": "code",
      "source": [
        "classifiers = [KNeighborsClassifier(), \n",
        "               LinearRegression(n_jobs=-1),\n",
        "               RandomForestClassifier(n_jobs=-1), \n",
        "               LinearSVC()]\n",
        "\n",
        "cv = KFold(n_splits=10, shuffle=True)\n",
        "train_data, test_data = create_meta_dataset(classifiers, X_train, X_test, y_train, cv)\n",
        "train_data[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [11:35<00:00, 205.38s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        , -0.07571379,  0.        ,  0.        ],\n",
              "       [ 1.        ,  0.74208088,  1.        ,  1.        ],\n",
              "       [ 1.        ,  0.39862334,  0.9       ,  0.        ],\n",
              "       [ 0.        ,  0.30014396,  0.1       ,  0.        ],\n",
              "       [ 0.        ,  0.62722099,  0.2       ,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "pzPIK6C3GpFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "276b0cb4-67b4-4ba2-8fbf-b0a2f2307eb6"
      },
      "cell_type": "code",
      "source": [
        "%time try_diffirent_feature_compositions(meta_classifiers, X_train, X_test, train_data, test_data, y_train, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 48s, sys: 769 ms, total: 1min 49s\n",
            "Wall time: 1min 35s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Meta features plus initial features</th>\n",
              "      <th>Only initial features</th>\n",
              "      <th>Only meta-features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.967399</td>\n",
              "      <td>0.967403</td>\n",
              "      <td>0.968211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>0.970295</td>\n",
              "      <td>0.776472</td>\n",
              "      <td>0.970219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.970687</td>\n",
              "      <td>0.943289</td>\n",
              "      <td>0.961070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Meta features plus initial features  \\\n",
              "KNeighborsClassifier                               0.967399   \n",
              "LinearRegression                                   0.970295   \n",
              "RandomForestClassifier                             0.970687   \n",
              "\n",
              "                        Only initial features  Only meta-features  \n",
              "KNeighborsClassifier                 0.967403            0.968211  \n",
              "LinearRegression                     0.776472            0.970219  \n",
              "RandomForestClassifier               0.943289            0.961070  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "p-ks6Fo4LlSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Увеличение числа фолдов почти не улучшило качество классификации."
      ]
    },
    {
      "metadata": {
        "id": "TMus76w3PjWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7ef7e835-8bd5-4934-b138-43c040e7042f"
      },
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(train_data, y_train)\n",
        "y_pred = lr.predict(test_data)\n",
        "print('linear model over meta dataset: ', accuracy_score(y_test, y_pred))\n",
        "print('averaging over meta dataset: ', accuracy_score(y_test, np.round(np.mean(test_data, axis=1))))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear model over meta dataset:  0.9714829281297083\n",
            "averaging over meta dataset:  0.9076224598196073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yo_yzGIgRTtS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Дает ли преимущество линейная модель? О чем говорят коэффициенты линейной модели в данном случае?**\n",
        "\n",
        "Линейная модель показывает намного более хороший результат, чем простое усреднение. Вообще, её результат лучший из всех предыдущих. Видимо, стоило так же рассматривать логистическую регрессию в качестве мета-классификатора."
      ]
    },
    {
      "metadata": {
        "id": "O4z770SRRhP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8c00cff7-3d40-4099-92e7-ffcc777a27bf"
      },
      "cell_type": "code",
      "source": [
        "lr.coef_ "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.43400692, -1.51068721,  5.02942403, -0.11047876]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "LcxLv-GJSJlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Коэффициенты линейной модели говорят о том, на сколько полезен тот или иной признак. Видно, что наибольший по модулю коэффициент приходится на KNeighborsClassifier(), что удивительно) "
      ]
    },
    {
      "metadata": {
        "id": "Gd2_d1AAHLsf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Поисковое ранжирование\n",
        "\n",
        "![](http://i.imgur.com/2QnD2nF.jpg)\n",
        "\n",
        "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
        " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
        " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
        " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
        "\n",
        "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
        "### Подходы к решению задачи ранжирования\n",
        "Существуют 3 основных подхода, различие между которыми в используемой функции потерь:\n",
        "  \n",
        "1. **Pointwise подход**. В этом случае рассматривается *один объект* (в случае поискового ранжирования - конкретный документ) и функция потерь считается только по нему. Любой стандартный классификатор или регрессор может решать pointwise задачу ранжирования, обучившись предсказывать значение таргета. Итоговое ранжирование получается после сортировки документов к одному запросу по предсказанию такой модели.\n",
        "2. **Pairwise подход**. В рамках данной модели функция потерь вычисляется по *паре объектов*. Другими словами, функция потерь штрафует модель, если отражированная этой моделью пара документов оказалась в неправильном порядке.\n",
        "3. **Listwise подход**. Этот подход использует все объекты для вычисления функции потерь, стараясь явно оптимизировать правильный порядок.\n",
        "\n",
        "### Оценка качества\n",
        "\n",
        "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
        "Для одного запроса DCG считается следующим образом:\n",
        "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
        "\n",
        "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
        "\n",
        "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
        "\n",
        "Итоговая формула для расчета *nDCG*:\n",
        "\n",
        "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
        "\n",
        "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
        "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
        "\n",
        "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
      ]
    },
    {
      "metadata": {
        "id": "PbJl73fYSH7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "XR2bDUDBHLsg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загрузите данные конкурса [Интернет-математика 2009](http://imat2009.yandex.ru/datasets). Там же находится описание данных. Сами данные можно скачать [здесь](https://www.dropbox.com/s/xj3g18s01m1euzl/imat2009.tar.bz2?dl=0). Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30. Обратите внимание на формат данных: разбивать необходимо множество запросов, а не строчки датасета."
      ]
    },
    {
      "metadata": {
        "id": "pYVBoB7YHLsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "135b2b82-92f9-4f49-e56c-f618617d9b92"
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/xj3g18s01m1euzl/imat2009.tar.bz2&ts=1489637334&use_mirror=excellmedia\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-22 10:48:49--  https://www.dropbox.com/s/xj3g18s01m1euzl/imat2009.tar.bz2\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/xj3g18s01m1euzl/imat2009.tar.bz2 [following]\n",
            "--2018-10-22 10:48:50--  https://www.dropbox.com/s/raw/xj3g18s01m1euzl/imat2009.tar.bz2\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com/cd/0/inline/ATo5R65U8qj0h6XOeZG2nno1X7Or-ka4rEgGiTrlhqKCon8Rs4_miAgTnP6_xCj9mCvnvWUSZgRhHShdSePO_K-HBRq5RH4Vu2cD4ZmcAHHrYG3cIABzZHC51EOdlMAOOdPCW4tqu7g5Ah3yiWd_wbLz832KWhAUBSoH4o2IEKEEbIhvs7MQRSPz5nE8aJ5nmNY/file [following]\n",
            "--2018-10-22 10:48:50--  https://ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com/cd/0/inline/ATo5R65U8qj0h6XOeZG2nno1X7Or-ka4rEgGiTrlhqKCon8Rs4_miAgTnP6_xCj9mCvnvWUSZgRhHShdSePO_K-HBRq5RH4Vu2cD4ZmcAHHrYG3cIABzZHC51EOdlMAOOdPCW4tqu7g5Ah3yiWd_wbLz832KWhAUBSoH4o2IEKEEbIhvs7MQRSPz5nE8aJ5nmNY/file\n",
            "Resolving ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com (ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com (ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/ATpTQUb0EcxWBDGr7-m3JrV56DUTDsRZnwkrRKnvyK6xxM0o7NhYd0tkzpF7mRNX7wCiroY8YYqdlB5AxWbsIdcYpvHQAoAzrAO1lnfoMi9rCEbWmORfdnqHwNo1GaI5bhfpch-LKTVmBNZZXLDTt9_fOqPYgoBgEB_BBHAY81_4EX1GKZqqqJl_EJTha9EKyxUFPkXqJ2hHJ_y2cTKuVbcU0fWbsxvF7jokb3Rb5HQE2zZQo6RB4PxXUyhnEIiO3A-4zT_p1_7jBfjW2aCgUi6AcWvdREnLjByV6fPFitADIiKgAWge8VcHprzPSvfcsQ12N5nNgJ_c2h15g1AtRKFlmqwZin-SPiP24E6wfiqSVfSC8Ftml_TUxPRBdTQQaLImdcIB1jrjEa7AovWQqgqU2ynHaPb7sA6GCVEO2siAbpZzddw6f9U0dAgvSp6vi3E/file [following]\n",
            "--2018-10-22 10:48:51--  https://ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com/cd/0/inline2/ATpTQUb0EcxWBDGr7-m3JrV56DUTDsRZnwkrRKnvyK6xxM0o7NhYd0tkzpF7mRNX7wCiroY8YYqdlB5AxWbsIdcYpvHQAoAzrAO1lnfoMi9rCEbWmORfdnqHwNo1GaI5bhfpch-LKTVmBNZZXLDTt9_fOqPYgoBgEB_BBHAY81_4EX1GKZqqqJl_EJTha9EKyxUFPkXqJ2hHJ_y2cTKuVbcU0fWbsxvF7jokb3Rb5HQE2zZQo6RB4PxXUyhnEIiO3A-4zT_p1_7jBfjW2aCgUi6AcWvdREnLjByV6fPFitADIiKgAWge8VcHprzPSvfcsQ12N5nNgJ_c2h15g1AtRKFlmqwZin-SPiP24E6wfiqSVfSC8Ftml_TUxPRBdTQQaLImdcIB1jrjEa7AovWQqgqU2ynHaPb7sA6GCVEO2siAbpZzddw6f9U0dAgvSp6vi3E/file\n",
            "Reusing existing connection to ucc18d6aa0fdf2c3825c119ad150.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44984588 (43M) [application/octet-stream]\n",
            "Saving to: ‘imat2009.tar.bz2’\n",
            "\n",
            "imat2009.tar.bz2    100%[===================>]  42.90M  45.4MB/s    in 0.9s    \n",
            "\n",
            "2018-10-22 10:48:52 (45.4 MB/s) - ‘imat2009.tar.bz2’ saved [44984588/44984588]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFGCU9h7WrYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "23ad2fca-4b22-41d9-81d1-fd8f8921e5b9"
      },
      "cell_type": "code",
      "source": [
        "!tar xvjf imat2009.tar.bz2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imat2009-datasets/\n",
            "imat2009-datasets/imat2009_test.txt\n",
            "imat2009-datasets/imat2009_learning.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9KMNcMIV5pS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('imat2009-datasets/imat2009_learning.txt') as f:\n",
        "    train_data = f.readlines()\n",
        "with open('imat2009-datasets/imat2009_test.txt') as f:\n",
        "    test_data = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbHfDBM5fpAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8ecb4faf-0a83-4c2d-8868-6c83dec023c8"
      },
      "cell_type": "code",
      "source": [
        "train_data[0][:100]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1 1:0.000023 7:0.704953 8:0.550315 9:0.032294 11:0.712631 14:0.015686 15:0.137255 16:0.302576 17:1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "ilYSjUMZXlVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_features(feature_arr):\n",
        "    features = np.zeros(245)\n",
        "    for line in feature_arr:\n",
        "        num, value = line.split(':')\n",
        "        features[int(num) - 1] = float(value)\n",
        "    return features\n",
        "\n",
        "  \n",
        "def create_dataset(data, is_train_data=False):\n",
        "    features, queries, relevances = [], [], []\n",
        "    \n",
        "    for line in data:\n",
        "        feature_array = line.strip().split()\n",
        "        relevances.append(feature_array[0])\n",
        "        features.append(extract_features(feature_array[1: -2]))\n",
        "        queries.append(feature_array[-1])\n",
        "        \n",
        "    df = pd.DataFrame(features)\n",
        "    df['query'] = queries\n",
        "    if is_train_data:\n",
        "        df['relevance'] = relevances\n",
        "    return df\n",
        "\n",
        "  \n",
        "def train_test_split_by_quieries(data):\n",
        "    all_train_data = create_dataset(data, is_train_data=True)\n",
        "    \n",
        "    queries = np.unique([line.strip().split()[-1] for line in data])\n",
        "    train_queries, test_queries = train_test_split(queries, train_size=0.7)\n",
        "\n",
        "    train_data = all_train_data[list(map(lambda q : q in train_queries, all_train_data['query']))]\n",
        "    test_data = all_train_data[list(map(lambda q : q in test_queries, all_train_data['query']))]\n",
        "    \n",
        "    columns_to_take = train_data.columns[:-1]\n",
        "    \n",
        "    return train_data[columns_to_take], test_data[columns_to_take], \\\n",
        "           train_data['relevance'].astype(float), test_data['relevance'].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lL_BMy0RX1CS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "1a8ed9dc-9aec-4cde-ae36-67874cc1d71e"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split_by_quieries(train_data)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((69018, 246), (28272, 246))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "39Ot_6H7LTbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "43236d55-2be1-49d7-f824-135c6e7a6322"
      },
      "cell_type": "code",
      "source": [
        "test_data_as_df = create_dataset(test_data)\n",
        "test_data_as_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.479999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.807433</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.42843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.754434</td>\n",
              "      <td>0.684276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005165</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.742314</td>\n",
              "      <td>0.576655</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001706</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 246 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2     3    4    5         6         7    8         9  ...    \\\n",
              "0  0.0  1.0  0.0  0.00  0.0  0.0  0.479999  0.000000  0.0  0.000000  ...     \n",
              "1  0.0  1.0  0.0  0.51  0.0  1.0  0.807433  0.000000  0.0  0.000000  ...     \n",
              "2  0.0  1.0  0.0  0.08  0.0  1.0  0.754434  0.684276  0.0  0.005165  ...     \n",
              "3  0.0  1.0  0.0  0.51  0.0  0.0  0.742314  0.576655  0.0  0.000000  ...     \n",
              "4  0.0  1.0  0.0  0.51  0.0  0.0  0.625239  0.000000  0.0  0.001706  ...     \n",
              "\n",
              "   236  237  238      239  240       241  242       243  244  query  \n",
              "0  0.0  0.0  0.0  0.00000  0.0  0.000000  0.0  1.000000  0.0  16427  \n",
              "1  0.0  0.0  0.0  0.42843  0.0  0.000000  0.0  0.933333  0.0  16427  \n",
              "2  0.0  0.0  0.0  0.00000  0.0  0.078431  0.0  0.949020  0.0  16427  \n",
              "3  0.0  0.0  0.0  0.00000  0.0  0.000000  0.0  0.803922  0.0  16427  \n",
              "4  0.0  0.0  0.0  0.00000  0.0  0.690196  0.0  1.000000  0.0  16427  \n",
              "\n",
              "[5 rows x 246 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "eWZochWTHLsl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам, где разбиение должно быть по запросам, а не строчкам датасета.\n",
        "\n",
        "**(1 балл) Задание 10.** *Pointwise* подход. Воспользовавшись известными вам техниками построения линейной регрессии, обучите модель, предсказывающую оценку асессора."
      ]
    },
    {
      "metadata": {
        "id": "VNAoRayAmTrW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Возьмём реализацию метрик, приведённую по ссылке в задании."
      ]
    },
    {
      "metadata": {
        "id": "Zx_4xplEHLsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    if gains == \"exponential\":\n",
        "        gains = 2 ** y_true - 1\n",
        "    elif gains == \"linear\":\n",
        "        gains = y_true\n",
        "    else:\n",
        "        raise ValueError(\"Invalid gains option.\")\n",
        "\n",
        "    # highest rank is 1 so +2 instead of +1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gains / discounts)\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_score, k=10, gains=\"exponential\"):\n",
        "    best = dcg_score(y_true, y_true, k, gains)\n",
        "    actual = dcg_score(y_true, y_score, k, gains)\n",
        "    if best == 0 and actual == 0:\n",
        "        return 1\n",
        "    return actual / best"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tpPcFwDf1q6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Посчитаем NCDG. Для каждого запроса считаем ndcg, потом усредняем"
      ]
    },
    {
      "metadata": {
        "id": "dD1gxkGWm1QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2363a390-efc1-4493-8381-ebe48fb1a926"
      },
      "cell_type": "code",
      "source": [
        "lr = LinearRegression(n_jobs=-1)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "ndcgs = []\n",
        "for q in np.unique(X_test['query']):\n",
        "    bool_idxs = (X_test['query'] == q)\n",
        "    ndcgs.append(ndcg_score(np.array(y_test[bool_idxs]), y_pred[bool_idxs]))\n",
        "    \n",
        "print('NDCG = {}'.format(np.mean(ndcgs)))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG = 0.8301642959109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWFzWF-JHLsq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Ранжируем с XGBoost\n",
        "\n",
        "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
        "1. **reg:linear** — данную функцию потерь можно использовать для решения задачи ранжирование *pointwise* подходом.\n",
        "2. **rank:pairwise** — в качестве *pairwise* модели в XGBoost реализован [RankNet](http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
        "3. **rank:map, rank:ndcg** — реализация [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) для двух метрик: [MAP](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса *listwise* моделей."
      ]
    },
    {
      "metadata": {
        "id": "WlT11GcIHLss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(2 балла) Задание 11.** Обучите модели **reg:linear**, **rank:pairwise** и **rank:ndcg**, в качестве метрики оценки качества (*eval_metric*) используя *nDCG*, а в качестве бустера решающее дерево. Настройте [параметры](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md) алгоритма и добейтесь высокого качества на тестовой выборке."
      ]
    },
    {
      "metadata": {
        "id": "SDg4Y95DPeEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "6ae17b63-1c40-402b-9fb8-4f2cf69adc08"
      },
      "cell_type": "code",
      "source": [
        "train_indices, train_lengths = [], []\n",
        "for name, group in pd.groupby(X_train, 'query'):\n",
        "    train_indices += list(group.index)\n",
        "    train_lengths.append(len(group))\n",
        "    \n",
        "test_indices, test_lengths = [], []\n",
        "for name, group in pd.groupby(X_test, 'query'):\n",
        "    test_indices += list(group.index)\n",
        "    test_lengths.append(len(group))\n",
        "\n",
        "X_train, y_train = X_train.loc[train_indices], y_train.loc[train_indices]\n",
        "X_test, y_test = X_test.loc[test_indices], y_test.loc[test_indices]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: pd.groupby() is deprecated and will be removed; Please use the Series.groupby() or DataFrame.groupby() methods\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: pd.groupby() is deprecated and will be removed; Please use the Series.groupby() or DataFrame.groupby() methods\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3TpZ21mxHLst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c5c886c8-34a3-4caf-f65c-f39070c07ba8"
      },
      "cell_type": "code",
      "source": [
        "train_dmatrix = DMatrix(X_train[X_train.columns[:-1]], y_train)\n",
        "valid_dmatrix = DMatrix(X_test[X_test.columns[:-1]], y_test)\n",
        "\n",
        "train_dmatrix.set_group(train_lengths)\n",
        "valid_dmatrix.set_group(test_lengths)\n",
        "\n",
        "params = {'objective': 'reg:linear', 'eval_metric' : 'ndcg'}\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100, verbose_eval=50, evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.833818\n",
            "[50]\tvalidation-ndcg:0.864369\n",
            "[99]\tvalidation-ndcg:0.86474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KyI4Dz2chCKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Подберем параметры."
      ]
    },
    {
      "metadata": {
        "id": "_lFfob00hFEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def search_for_one_param(param_name, param_list, objective):\n",
        "    for param in param_list:\n",
        "        print('{} = {}'.format(param_name, param))\n",
        "        params = {\n",
        "            'objective': objective,\n",
        "            param_name: param,\n",
        "            'eval_metric' : 'ndcg'\n",
        "        }\n",
        "        xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100, verbose_eval=100,\n",
        "                               evals=[(valid_dmatrix, 'validation')])\n",
        "        print()\n",
        "    print()\n",
        "\n",
        "        \n",
        "def search_for_two_params(first_param_name, first_param_list, \n",
        "                          second_param_name, second_param_list, objective):\n",
        "    for first_param in first_param_list:\n",
        "        for second_param in second_param_list:\n",
        "            print('{} = {}, {} = {}'.format(first_param_name, first_param, second_param_name, second_param))\n",
        "            params = {\n",
        "                'objective': objective,\n",
        "                first_param_name: first_param,\n",
        "                second_param_name: second_param,\n",
        "                'eval_metric' : 'ndcg'\n",
        "            }\n",
        "            xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100, verbose_eval=100,\n",
        "                                   evals=[(valid_dmatrix, 'validation')])\n",
        "            print()\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_9IwVkXk1CT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "ae8d099d-fbc9-44b0-8da6-6d01b52bab61"
      },
      "cell_type": "code",
      "source": [
        "search_for_one_param('lambda', np.linspace(0, 25, 10), objective='reg:linear')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = 0.0\n",
            "[0]\tvalidation-ndcg:0.833465\n",
            "[99]\tvalidation-ndcg:0.862398\n",
            "\n",
            "lambda = 2.7777777777777777\n",
            "[0]\tvalidation-ndcg:0.833833\n",
            "[99]\tvalidation-ndcg:0.864841\n",
            "\n",
            "lambda = 5.555555555555555\n",
            "[0]\tvalidation-ndcg:0.832397\n",
            "[99]\tvalidation-ndcg:0.867538\n",
            "\n",
            "lambda = 8.333333333333332\n",
            "[0]\tvalidation-ndcg:0.831546\n",
            "[99]\tvalidation-ndcg:0.86712\n",
            "\n",
            "lambda = 11.11111111111111\n",
            "[0]\tvalidation-ndcg:0.832445\n",
            "[99]\tvalidation-ndcg:0.86691\n",
            "\n",
            "lambda = 13.88888888888889\n",
            "[0]\tvalidation-ndcg:0.832177\n",
            "[99]\tvalidation-ndcg:0.868584\n",
            "\n",
            "lambda = 16.666666666666664\n",
            "[0]\tvalidation-ndcg:0.832304\n",
            "[99]\tvalidation-ndcg:0.867692\n",
            "\n",
            "lambda = 19.444444444444443\n",
            "[0]\tvalidation-ndcg:0.831389\n",
            "[99]\tvalidation-ndcg:0.869353\n",
            "\n",
            "lambda = 22.22222222222222\n",
            "[0]\tvalidation-ndcg:0.832794\n",
            "[99]\tvalidation-ndcg:0.867104\n",
            "\n",
            "lambda = 25.0\n",
            "[0]\tvalidation-ndcg:0.832034\n",
            "[99]\tvalidation-ndcg:0.867854\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBZiqI56dm5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Лучший результат: lambda =13.88888888888889."
      ]
    },
    {
      "metadata": {
        "id": "dQCR1uu4mJk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "32b6a200-8d85-40dd-e654-368041d689a8"
      },
      "cell_type": "code",
      "source": [
        "search_for_two_params('max_depth', range(3, 10, 2), 'min_child_weight', [4, 5, 6], objective='reg:linear')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_depth = 3, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.814671\n",
            "[99]\tvalidation-ndcg:0.865415\n",
            "\n",
            "max_depth = 3, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.814671\n",
            "[99]\tvalidation-ndcg:0.865554\n",
            "\n",
            "max_depth = 3, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.814671\n",
            "[99]\tvalidation-ndcg:0.865455\n",
            "\n",
            "max_depth = 5, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.82738\n",
            "[99]\tvalidation-ndcg:0.866944\n",
            "\n",
            "max_depth = 5, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.82738\n",
            "[99]\tvalidation-ndcg:0.867447\n",
            "\n",
            "max_depth = 5, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.827453\n",
            "[99]\tvalidation-ndcg:0.867801\n",
            "\n",
            "max_depth = 7, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.836616\n",
            "[99]\tvalidation-ndcg:0.864236\n",
            "\n",
            "max_depth = 7, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.836346\n",
            "[99]\tvalidation-ndcg:0.862354\n",
            "\n",
            "max_depth = 7, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.836435\n",
            "[99]\tvalidation-ndcg:0.863897\n",
            "\n",
            "max_depth = 9, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.836524\n",
            "[99]\tvalidation-ndcg:0.858669\n",
            "\n",
            "max_depth = 9, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.8365\n",
            "[99]\tvalidation-ndcg:0.856214\n",
            "\n",
            "max_depth = 9, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.836279\n",
            "[99]\tvalidation-ndcg:0.858417\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEyBepWCaGic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "best parameters:  \n",
        "\n",
        "max_depth = 5, min_child_weight = 6  \n",
        "[0]\tvalidation-ndcg:0.827453  \n",
        "[99]\tvalidation-ndcg:0.867801  "
      ]
    },
    {
      "metadata": {
        "id": "ldrL25zbaiIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "187512ab-6aa0-4d44-f22d-32e599fc158c"
      },
      "cell_type": "code",
      "source": [
        "search_for_one_param('gamma', [i / 10.0 for i in range(0, 5)], objective='reg:linear')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gamma = 0.0\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.86474\n",
            "\n",
            "gamma = 0.1\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.866566\n",
            "\n",
            "gamma = 0.2\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.86384\n",
            "\n",
            "gamma = 0.3\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.864398\n",
            "\n",
            "gamma = 0.4\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.864359\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yl1FTxz38oOY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "best parameter:\n",
        "\n",
        "gamma = 0.1  \n",
        "[0]\tvalidation-ndcg:0.833818  \n",
        "[99]\tvalidation-ndcg:0.866566  "
      ]
    },
    {
      "metadata": {
        "id": "Qnm26HY4bGXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1243
        },
        "outputId": "0c792f30-5c51-43b6-8f52-44a238eb9691"
      },
      "cell_type": "code",
      "source": [
        "search_for_two_params('subsample', [i / 10.0 for i in range(6, 10)], \n",
        "                      'colsample_bytree', [i / 10.0 for i in range(6, 10)], \n",
        "                       objective='reg:linear')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subsample = 0.6, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.830057\n",
            "[99]\tvalidation-ndcg:0.864258\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.832561\n",
            "[99]\tvalidation-ndcg:0.86128\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.830918\n",
            "[99]\tvalidation-ndcg:0.862593\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.831695\n",
            "[99]\tvalidation-ndcg:0.860113\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.829329\n",
            "[99]\tvalidation-ndcg:0.863537\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.834767\n",
            "[99]\tvalidation-ndcg:0.866846\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.834115\n",
            "[99]\tvalidation-ndcg:0.863773\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.832109\n",
            "[99]\tvalidation-ndcg:0.861671\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.826272\n",
            "[99]\tvalidation-ndcg:0.863523\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.830598\n",
            "[99]\tvalidation-ndcg:0.862834\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.830292\n",
            "[99]\tvalidation-ndcg:0.862999\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.830552\n",
            "[99]\tvalidation-ndcg:0.863199\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.82454\n",
            "[99]\tvalidation-ndcg:0.865199\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.832736\n",
            "[99]\tvalidation-ndcg:0.865304\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.830895\n",
            "[99]\tvalidation-ndcg:0.864672\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.830456\n",
            "[99]\tvalidation-ndcg:0.866588\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "82YvjmQGcQwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "best result:   \n",
        "\n",
        "subsample = 0.7, colsample_bytree = 0.7  \n",
        "[0]\tvalidation-ndcg:0.834767  \n",
        "[99]\tvalidation-ndcg:0.866846  "
      ]
    },
    {
      "metadata": {
        "id": "rCraayswcjEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "208cd480-2d9d-4cdc-9b31-133e65f49576"
      },
      "cell_type": "code",
      "source": [
        "search_for_one_param('reg_alpha', [0, 0.001, 0.005, 0.01, 0.05], objective='reg:linear')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reg_alpha = 0\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.86474\n",
            "\n",
            "reg_alpha = 0.001\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.863871\n",
            "\n",
            "reg_alpha = 0.005\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.865645\n",
            "\n",
            "reg_alpha = 0.01\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.864793\n",
            "\n",
            "reg_alpha = 0.05\n",
            "[0]\tvalidation-ndcg:0.833818\n",
            "[99]\tvalidation-ndcg:0.863561\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5rcQTa4dAZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Можно взять alpha =  0.01, её результат validation-ndcg:0.833818"
      ]
    },
    {
      "metadata": {
        "id": "EqwxFqSuddlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b773c843-b8c3-4cd5-a6e4-3a56743dc9c7"
      },
      "cell_type": "code",
      "source": [
        "params = {'objective': 'reg:linear’,\n",
        "\t\t'eval_metric' : 'ndcg'\n",
        "\t\t'lambda': 13.88888888888889,\n",
        "\t\t'gamma': 0.1,\n",
        "\t\t 'max_depth': 5, \n",
        "\t\t'min_child_weight' : 6,\n",
        "\t\t 'subsample': 0.7,\n",
        "                 'colsample_bytree': 0.7,\n",
        "\t\t'reg_alpha': 0.01}\n",
        "\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100, verbose_eval=50,\n",
        "                      evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.835159\n",
            "[50]\tvalidation-ndcg:0.862947\n",
            "[99]\tvalidation-ndcg:0.863061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dsx9N2NvfJ7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Это хуже предыдущего результата.\n",
        "\n",
        "[0]\tvalidation-ndcg:0.833818  \n",
        "[50]\tvalidation-ndcg:0.864369  \n",
        "[99]\tvalidation-ndcg:0.86474  "
      ]
    },
    {
      "metadata": {
        "id": "2YsA5c7LgJkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Лучший результат на валидации для pointwise подхода в итоге: validation-ndcg:0.86474.   \n",
        "\n",
        "Запустим валидацию с параметрами по умолчанию для rank:pairwise"
      ]
    },
    {
      "metadata": {
        "id": "1o4ExakqKp_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b8e84020-cc31-4219-fccf-9139789df963"
      },
      "cell_type": "code",
      "source": [
        "params = {'objective': 'rank:pairwise', 'eval_metric' : 'ndcg'}\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100, verbose_eval=50,\n",
        "                           evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.826776\n",
            "[50]\tvalidation-ndcg:0.870235\n",
            "[99]\tvalidation-ndcg:0.87173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3z4LYcM3pFOu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Подберём параметры."
      ]
    },
    {
      "metadata": {
        "id": "trynvTHXgvwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "dae10b5b-f06e-44d6-eac4-16663f7bdb50"
      },
      "cell_type": "code",
      "source": [
        "objective = 'rank:pairwise'\n",
        "search_for_one_param('lambda', np.linspace(0, 25, 10), objective=objective)\n",
        "search_for_two_params('max_depth', range(3, 10, 2), 'min_child_weight', [4, 5, 6], objective=objective)\n",
        "search_for_one_param('gamma', [i / 10.0 for i in range(0, 5)], objective=objective)\n",
        "search_for_two_params('subsample', [i / 10.0 for i in range(6, 10)], \n",
        "                      'colsample_bytree', [i / 10.0 for i in range(6, 10)], \n",
        "                       objective=objective)\n",
        "search_for_one_param('reg_alpha', [0, 0.001, 0.005, 0.01, 0.05], objective=objective)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = 0.0\n",
            "[0]\tvalidation-ndcg:0.826595\n",
            "[99]\tvalidation-ndcg:0.86956\n",
            "\n",
            "lambda = 2.7777777777777777\n",
            "[0]\tvalidation-ndcg:0.826277\n",
            "[99]\tvalidation-ndcg:0.87082\n",
            "\n",
            "lambda = 5.555555555555555\n",
            "[0]\tvalidation-ndcg:0.825881\n",
            "[99]\tvalidation-ndcg:0.870861\n",
            "\n",
            "lambda = 8.333333333333332\n",
            "[0]\tvalidation-ndcg:0.82471\n",
            "[99]\tvalidation-ndcg:0.869596\n",
            "\n",
            "lambda = 11.11111111111111\n",
            "[0]\tvalidation-ndcg:0.824727\n",
            "[99]\tvalidation-ndcg:0.870992\n",
            "\n",
            "lambda = 13.88888888888889\n",
            "[0]\tvalidation-ndcg:0.824776\n",
            "[99]\tvalidation-ndcg:0.870065\n",
            "\n",
            "lambda = 16.666666666666664\n",
            "[0]\tvalidation-ndcg:0.824776\n",
            "[99]\tvalidation-ndcg:0.872437\n",
            "\n",
            "lambda = 19.444444444444443\n",
            "[0]\tvalidation-ndcg:0.825033\n",
            "[99]\tvalidation-ndcg:0.870377\n",
            "\n",
            "lambda = 22.22222222222222\n",
            "[0]\tvalidation-ndcg:0.824938\n",
            "[99]\tvalidation-ndcg:0.87291\n",
            "\n",
            "lambda = 25.0\n",
            "[0]\tvalidation-ndcg:0.824873\n",
            "[99]\tvalidation-ndcg:0.873696\n",
            "\n",
            "\n",
            "max_depth = 3, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.817668\n",
            "[99]\tvalidation-ndcg:0.868179\n",
            "\n",
            "max_depth = 3, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.817668\n",
            "[99]\tvalidation-ndcg:0.867683\n",
            "\n",
            "max_depth = 3, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.817668\n",
            "[99]\tvalidation-ndcg:0.867513\n",
            "\n",
            "max_depth = 5, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.821323\n",
            "[99]\tvalidation-ndcg:0.872159\n",
            "\n",
            "max_depth = 5, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.821323\n",
            "[99]\tvalidation-ndcg:0.871979\n",
            "\n",
            "max_depth = 5, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.821323\n",
            "[99]\tvalidation-ndcg:0.871047\n",
            "\n",
            "max_depth = 7, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.82947\n",
            "[99]\tvalidation-ndcg:0.86838\n",
            "\n",
            "max_depth = 7, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.829412\n",
            "[99]\tvalidation-ndcg:0.870336\n",
            "\n",
            "max_depth = 7, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.82948\n",
            "[99]\tvalidation-ndcg:0.870442\n",
            "\n",
            "max_depth = 9, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.82678\n",
            "[99]\tvalidation-ndcg:0.866646\n",
            "\n",
            "max_depth = 9, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.827151\n",
            "[99]\tvalidation-ndcg:0.866663\n",
            "\n",
            "max_depth = 9, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.826975\n",
            "[99]\tvalidation-ndcg:0.868323\n",
            "\n",
            "\n",
            "gamma = 0.0\n",
            "[0]\tvalidation-ndcg:0.826776\n",
            "[99]\tvalidation-ndcg:0.87173\n",
            "\n",
            "gamma = 0.1\n",
            "[0]\tvalidation-ndcg:0.826775\n",
            "[99]\tvalidation-ndcg:0.871425\n",
            "\n",
            "gamma = 0.2\n",
            "[0]\tvalidation-ndcg:0.826775\n",
            "[99]\tvalidation-ndcg:0.870596\n",
            "\n",
            "gamma = 0.3\n",
            "[0]\tvalidation-ndcg:0.826775\n",
            "[99]\tvalidation-ndcg:0.870753\n",
            "\n",
            "gamma = 0.4\n",
            "[0]\tvalidation-ndcg:0.826775\n",
            "[99]\tvalidation-ndcg:0.870781\n",
            "\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.823108\n",
            "[99]\tvalidation-ndcg:0.871198\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.825474\n",
            "[99]\tvalidation-ndcg:0.868464\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.826467\n",
            "[99]\tvalidation-ndcg:0.872068\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.822588\n",
            "[99]\tvalidation-ndcg:0.870336\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.823677\n",
            "[99]\tvalidation-ndcg:0.870873\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.821749\n",
            "[99]\tvalidation-ndcg:0.870897\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.823406\n",
            "[99]\tvalidation-ndcg:0.871415\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.823986\n",
            "[99]\tvalidation-ndcg:0.869099\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.825332\n",
            "[99]\tvalidation-ndcg:0.872161\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.82377\n",
            "[99]\tvalidation-ndcg:0.871812\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.825748\n",
            "[99]\tvalidation-ndcg:0.867392\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.826482\n",
            "[99]\tvalidation-ndcg:0.872962\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.82206\n",
            "[99]\tvalidation-ndcg:0.871878\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.822257\n",
            "[99]\tvalidation-ndcg:0.8697\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.821719\n",
            "[99]\tvalidation-ndcg:0.870234\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.825936\n",
            "[99]\tvalidation-ndcg:0.869402\n",
            "\n",
            "\n",
            "reg_alpha = 0\n",
            "[0]\tvalidation-ndcg:0.826776\n",
            "[99]\tvalidation-ndcg:0.87173\n",
            "\n",
            "reg_alpha = 0.001\n",
            "[0]\tvalidation-ndcg:0.826776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m1KPeWhNm1BD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "30b37d98-424f-490e-ebcd-895f130708d0"
      },
      "cell_type": "code",
      "source": [
        "params = {'objective': 'rank:pairwise',\n",
        "\t\t'eval_metric' : 'ndcg',\n",
        "\t\t'lambda': 0, \n",
        "\t\t 'max_depth': 7,\n",
        "\t\t'gamma': 0,\n",
        "\t\t'min_child_weight' : 6,\n",
        "\t\t 'subsample': 0.8,\n",
        "     'colsample_bytree': 0.9,\n",
        "\t\t'reg_alpha': 0.01}\n",
        "\n",
        "\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=4,\n",
        "                           evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.826863\n",
            "[1]\tvalidation-ndcg:0.837534\n",
            "[2]\tvalidation-ndcg:0.842911\n",
            "[3]\tvalidation-ndcg:0.843957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0IE0y5k0nOBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Прошлый результат был лучше.  \n",
        "\n",
        "[0]\tvalidation-ndcg:0.831313  \n",
        "[1]\tvalidation-ndcg:0.840101  \n",
        "[2]\tvalidation-ndcg:0.845807  \n",
        "[3]\tvalidation-ndcg:0.851514  \n"
      ]
    },
    {
      "metadata": {
        "id": "cacd5qASYim3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "ee7cef73-f4a9-4d42-9e09-99462863a318"
      },
      "cell_type": "code",
      "source": [
        "params = {'objective': 'rank:ndcg', 'eval_metric' : 'ndcg'}\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=4,\n",
        "                           evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.838937\n",
            "[1]\tvalidation-ndcg:0.84245\n",
            "[2]\tvalidation-ndcg:0.842455\n",
            "[3]\tvalidation-ndcg:0.845526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhAt1J9lndnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3734
        },
        "outputId": "a7414edd-5496-4853-bfd0-02e3b7dfb50a"
      },
      "cell_type": "code",
      "source": [
        "objective = 'rank:ndcg'\n",
        "search_for_one_param('lambda', np.linspace(0, 25, 10), objective=objective)\n",
        "search_for_two_params('max_depth', range(3, 10, 2), 'min_child_weight', [4, 5, 6], objective=objective)\n",
        "search_for_one_param('gamma', [i / 10.0 for i in range(0, 5)], objective=objective)\n",
        "search_for_two_params('subsample', [i / 10.0 for i in range(6, 10)], \n",
        "                      'colsample_bytree', [i / 10.0 for i in range(6, 10)], \n",
        "                       objective=objective)\n",
        "search_for_one_param('reg_alpha', [0, 0.001, 0.005, 0.01, 0.05], objective=objective)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = 0.0\n",
            "[0]\tvalidation-ndcg:0.829762\n",
            "[99]\tvalidation-ndcg:0.868528\n",
            "\n",
            "lambda = 2.7777777777777777\n",
            "[0]\tvalidation-ndcg:0.830847\n",
            "[99]\tvalidation-ndcg:0.868187\n",
            "\n",
            "lambda = 5.555555555555555\n",
            "[0]\tvalidation-ndcg:0.832971\n",
            "[99]\tvalidation-ndcg:0.86817\n",
            "\n",
            "lambda = 8.333333333333332\n",
            "[0]\tvalidation-ndcg:0.832983\n",
            "[99]\tvalidation-ndcg:0.866062\n",
            "\n",
            "lambda = 11.11111111111111\n",
            "[0]\tvalidation-ndcg:0.832736\n",
            "[99]\tvalidation-ndcg:0.871226\n",
            "\n",
            "lambda = 13.88888888888889\n",
            "[0]\tvalidation-ndcg:0.832596\n",
            "[99]\tvalidation-ndcg:0.870343\n",
            "\n",
            "lambda = 16.666666666666664\n",
            "[0]\tvalidation-ndcg:0.831487\n",
            "[99]\tvalidation-ndcg:0.870221\n",
            "\n",
            "lambda = 19.444444444444443\n",
            "[0]\tvalidation-ndcg:0.833418\n",
            "[99]\tvalidation-ndcg:0.870462\n",
            "\n",
            "lambda = 22.22222222222222\n",
            "[0]\tvalidation-ndcg:0.833159\n",
            "[99]\tvalidation-ndcg:0.869664\n",
            "\n",
            "lambda = 25.0\n",
            "[0]\tvalidation-ndcg:0.832958\n",
            "[99]\tvalidation-ndcg:0.868203\n",
            "\n",
            "\n",
            "max_depth = 3, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.822615\n",
            "[99]\tvalidation-ndcg:0.863936\n",
            "\n",
            "max_depth = 3, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.822615\n",
            "[99]\tvalidation-ndcg:0.863981\n",
            "\n",
            "max_depth = 3, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.822615\n",
            "[99]\tvalidation-ndcg:0.864639\n",
            "\n",
            "max_depth = 5, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.828762\n",
            "[99]\tvalidation-ndcg:0.868132\n",
            "\n",
            "max_depth = 5, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.829335\n",
            "[99]\tvalidation-ndcg:0.86701\n",
            "\n",
            "max_depth = 5, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.82937\n",
            "[99]\tvalidation-ndcg:0.867824\n",
            "\n",
            "max_depth = 7, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.830765\n",
            "[99]\tvalidation-ndcg:0.866729\n",
            "\n",
            "max_depth = 7, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.830835\n",
            "[99]\tvalidation-ndcg:0.868643\n",
            "\n",
            "max_depth = 7, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.830204\n",
            "[99]\tvalidation-ndcg:0.867963\n",
            "\n",
            "max_depth = 9, min_child_weight = 4\n",
            "[0]\tvalidation-ndcg:0.826948\n",
            "[99]\tvalidation-ndcg:0.868369\n",
            "\n",
            "max_depth = 9, min_child_weight = 5\n",
            "[0]\tvalidation-ndcg:0.828061\n",
            "[99]\tvalidation-ndcg:0.869462\n",
            "\n",
            "max_depth = 9, min_child_weight = 6\n",
            "[0]\tvalidation-ndcg:0.828125\n",
            "[99]\tvalidation-ndcg:0.86697\n",
            "\n",
            "\n",
            "gamma = 0.0\n",
            "[0]\tvalidation-ndcg:0.829617\n",
            "[99]\tvalidation-ndcg:0.867046\n",
            "\n",
            "gamma = 0.1\n",
            "[0]\tvalidation-ndcg:0.82956\n",
            "[99]\tvalidation-ndcg:0.867843\n",
            "\n",
            "gamma = 0.2\n",
            "[0]\tvalidation-ndcg:0.829659\n",
            "[99]\tvalidation-ndcg:0.866517\n",
            "\n",
            "gamma = 0.3\n",
            "[0]\tvalidation-ndcg:0.829659\n",
            "[99]\tvalidation-ndcg:0.868849\n",
            "\n",
            "gamma = 0.4\n",
            "[0]\tvalidation-ndcg:0.829644\n",
            "[99]\tvalidation-ndcg:0.869098\n",
            "\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.820626\n",
            "[99]\tvalidation-ndcg:0.865612\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.82656\n",
            "[99]\tvalidation-ndcg:0.865377\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.827055\n",
            "[99]\tvalidation-ndcg:0.865851\n",
            "\n",
            "subsample = 0.6, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.825354\n",
            "[99]\tvalidation-ndcg:0.864704\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.82438\n",
            "[99]\tvalidation-ndcg:0.866701\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.825235\n",
            "[99]\tvalidation-ndcg:0.86723\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.82461\n",
            "[99]\tvalidation-ndcg:0.863879\n",
            "\n",
            "subsample = 0.7, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.825506\n",
            "[99]\tvalidation-ndcg:0.867937\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.825529\n",
            "[99]\tvalidation-ndcg:0.864815\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.828273\n",
            "[99]\tvalidation-ndcg:0.866745\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.82761\n",
            "[99]\tvalidation-ndcg:0.86543\n",
            "\n",
            "subsample = 0.8, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.828058\n",
            "[99]\tvalidation-ndcg:0.868357\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.6\n",
            "[0]\tvalidation-ndcg:0.825781\n",
            "[99]\tvalidation-ndcg:0.86888\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.7\n",
            "[0]\tvalidation-ndcg:0.828489\n",
            "[99]\tvalidation-ndcg:0.866025\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.8\n",
            "[0]\tvalidation-ndcg:0.825832\n",
            "[99]\tvalidation-ndcg:0.867179\n",
            "\n",
            "subsample = 0.9, colsample_bytree = 0.9\n",
            "[0]\tvalidation-ndcg:0.825727\n",
            "[99]\tvalidation-ndcg:0.865739\n",
            "\n",
            "\n",
            "reg_alpha = 0\n",
            "[0]\tvalidation-ndcg:0.829617\n",
            "[99]\tvalidation-ndcg:0.867046\n",
            "\n",
            "reg_alpha = 0.001\n",
            "[0]\tvalidation-ndcg:0.829617\n",
            "[99]\tvalidation-ndcg:0.870684\n",
            "\n",
            "reg_alpha = 0.005\n",
            "[0]\tvalidation-ndcg:0.829617\n",
            "[99]\tvalidation-ndcg:0.868004\n",
            "\n",
            "reg_alpha = 0.01\n",
            "[0]\tvalidation-ndcg:0.829504\n",
            "[99]\tvalidation-ndcg:0.869509\n",
            "\n",
            "reg_alpha = 0.05\n",
            "[0]\tvalidation-ndcg:0.831384\n",
            "[99]\tvalidation-ndcg:0.866936\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9uh8ay4Vor0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "c2accb73-73f4-4875-d02a-58aae1f7e4ba"
      },
      "cell_type": "code",
      "source": [
        "params = {'objective': 'rank:ndcg’,\n",
        " \t\t'eval_metric' : 'ndcg',\n",
        "\t\t'lambda': 11.11111111111111, \n",
        "\t\t 'max_depth': 9,\n",
        "\t\t'gamma': 0.2,\n",
        "\t\t'min_child_weight' : 5,\n",
        "\t\t 'subsample': 0.9,\n",
        "     'colsample_bytree': 0.6,\n",
        "\t\t'reg_alpha': 0.001}\n",
        "\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=4,\n",
        "                           evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation-ndcg:0.827323\n",
            "[1]\tvalidation-ndcg:0.837183\n",
            "[2]\tvalidation-ndcg:0.843077\n",
            "[3]\tvalidation-ndcg:0.844363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PvKJQ3Yho5bP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "И снова хуже, чем предыдущий результат.\n",
        "\n",
        "[0]\tvalidation-ndcg:0.838937  \n",
        "[1]\tvalidation-ndcg:0.84245  \n",
        "[2]\tvalidation-ndcg:0.842455  \n",
        "[3]\tvalidation-ndcg:0.845526  "
      ]
    },
    {
      "metadata": {
        "id": "uQY7l70dHLs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Пользовательская функция потерь\n",
        "\n",
        "Библиотека XGBoost позволяет использовать пользовательские функции потерь. Для этого необходимо реализовать функцию, принимающую на вход вектор предсказанных значений и обучающую выборку, и возвращающую градиент и гессиан, посчитанный по входным данным.\n",
        "\n",
        "Важно отметить, что XGBoost использует диагональную аппроксимацию гессиана, таким образом все недиагональные элементы считаются малозначимыми и приравниваются нулю, поэтому и градиент, и гессиан являются векторами длины размера обучающей выборки.\n",
        "\n",
        "**(4 балла) Задание 12.** Реализуйте экспоненциальную функцию потерь для XGBoost:\n",
        "$$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = e^{-M} $$\n",
        "\n",
        "Обучите модель с помощью данной функции потерь, настройте параметры."
      ]
    },
    {
      "metadata": {
        "id": "oTU6nuNUHLs5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Комментарии к реализации**\n",
        "\n",
        "В случае ранжирования XGBoost'у необходимо знать о разбиении всех объектов на группы. В нашем случае в одну группу будут входить документы, соответствующие одному запросу. Функция, считающая градиент и гессиан по данным, должна знать данное разбиение датасета. Однако питоновский интерфейс класса *DMatrix* (в котором хранится датасет) не дает возможности получить это разбиение. В этом случае нужно реализовать функцию потерь в качестве функтора, конструктор которого принимает разбиение на группы в качестве параметра.\n",
        "\n",
        "Пример реализации своей функции потерь можно найти на соответствующем семинаре."
      ]
    },
    {
      "metadata": {
        "id": "xEaO-McTHLs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ExponentialPairwiseLoss(object):\n",
        "    def __init__(self, groups):\n",
        "        self.groups = groups\n",
        "                        \n",
        "    def __call__(self, preds, dtrain):\n",
        "        # your code here\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ULStJIqHLtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dmatrix = DMatrix(X_train[X_train.columns[:-1]], y_train)\n",
        "valid_dmatrix = DMatrix(X_test[X_test.columns[:-1]], y_test)\n",
        "\n",
        "train_dmatrix.set_group(train_lengths)\n",
        "valid_dmatrix.set_group(test_lengths)\n",
        "\n",
        "params = {'objective': 'reg:linear', 'eval_metric' : 'ndcg'}\n",
        "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=4,\n",
        "                           evals=[(valid_dmatrix, 'validation')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YBsE_6P9i2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "df83764d-9df0-4091-a183-f8d95fc733a0"
      },
      "cell_type": "code",
      "source": [
        "train_dmatrix.get_label()[:50]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n",
              "       1. , 2. , 0. , 0. , 0. , 0. , 2. , 1. , 1. , 0. , 0. , 0. , 0. ,\n",
              "       1. , 2. , 2. , 1. , 1. , 1. , 1. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
              "       0. , 2.5, 0. , 0. , 1. , 0. , 1. , 0. , 0. , 0. , 0. ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "X7iODiPrHLtG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(1 балл) Задание 13.** Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:\n",
        "  - какая модель работает лучше всего для данной задачи? \n",
        "  - в чем достоинства/недостатки каждой? \n",
        "  - сравните модели между собой: \n",
        "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
        "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
      ]
    },
    {
      "metadata": {
        "id": "TwJDRvjeS_4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Лучший результат пока что показал pointwise-подход с бустингом: validation-ndcg:0.854367."
      ]
    },
    {
      "metadata": {
        "id": "W9C6Ll3EHLtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}